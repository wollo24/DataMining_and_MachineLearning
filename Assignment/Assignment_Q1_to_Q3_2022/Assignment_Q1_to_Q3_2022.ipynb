{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af19791f",
      "metadata": {
        "id": "af19791f"
      },
      "source": [
        "# Data Mining and Machine Learning - Assignment questions 1 to 3\n",
        "\n",
        "> Topics Covered: Data Cleaning, Exploratory Data Analysis, Visualization and Regression \n",
        "\n",
        "**Due: Oct 23 @23.59 (Lausanne Time)**\n",
        "\n",
        "\n",
        "This assignment is the opportunity to apply the different concepts seen in class so far to a new dataset on the life expectancy.\n",
        "\n",
        "Run the first few cells to load the dataset and then get started with the questions! **Pay attention:** in order to start working, open the notebook in Colab, and make sure to make a copy of the notebook in your private Google Drive. After you finished, export the notebook as a .ipynb file and upload it on Moodle (Section \"Assignment\").\n",
        "\n",
        "To complete the assignment you have to do ***both***:\n",
        "\n",
        "1. Complete the exercises and submit your Python notebook\n",
        "2. Answer the questions to the quiz on Moodle\n",
        ">Note: You can only complete the quiz one time. Have your notebook with the answers ready for answering the quiz. The quiz will be made available Monday 10th October at 7p.m.\n",
        "\n",
        "Only the quiz questions accounts for your grade. Nevertheless, the answers to the quiz should be supported by your code in the notebook. If they are not, you will not receive points for them. \n",
        "\n",
        "**IMPORTANT!** You can discuss the questions with other students but **do not exchange code!** This is individual work. We will run your code and check for similarities. In case of high similarity scores between two notebooks, both the authors will get 0 points for the assignment.\n",
        "\n",
        "You can post your questions in slack channel #assignments.\n",
        "\n",
        "\n",
        "If there is need for further clarifications on the questions, after the assignment is released, we will update the file on GitHub, so make sure you check the git repo of the class for updates.\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5400e551",
      "metadata": {
        "id": "5400e551"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/michalis0/DataMining_and_MachineLearning/blob/master/Assignment/Assignment_Q1_to_Q3_2022/Assignment_Q1_to_Q3_2022.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a9c653d4",
      "metadata": {
        "id": "a9c653d4"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "sns.set_style(\"whitegrid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ac8305d0",
      "metadata": {
        "id": "ac8305d0",
        "outputId": "838c32b1-8454-47f1-c6b7-a8af2162eb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c7aa6f5d2b35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Life Expectancy Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Life Expectancy Data.csv'"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "df = pd.read_csv(\"Life Expectancy Data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20330efe",
      "metadata": {
        "id": "20330efe"
      },
      "source": [
        "For this assignment, we use data gathered by the WHO (World Health Organization) regarding many countries, over several years. The dataset includes information on items purchased from this store, including for each item or article:\n",
        "* **Country**\n",
        "* **Year**: year of the measurement\n",
        "* **Status**: Developed or Developing status\n",
        "* **Life expectancy**: Life Expectancy in years\n",
        "* **Adult Mortality**: Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n",
        "* **Alcohol**: Alcohol, recorded per capita (individuals aged 15+) consumption (in litres of pure alcohol)\n",
        "* **Hepatitis B**: Hepatitis B (HepB) immunization coverage among 1-year-olds (%)\n",
        "* **Measles**: Measles - number of reported cases per 1000 population\n",
        "* **BMI**: Average Body Mass Index of entire population\n",
        "* **under-five deaths**: Number of under-five deaths per 1000 population\n",
        "* **Polio**: Polio (Pol3) immunization coverage among 1-year-olds (%)\n",
        "* **Total expenditure**: General government expenditure on health as a percentage of total government expenditure (%)\n",
        "* **Diphtheria**: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n",
        "* **HIV/AIDS**: Deaths per 1 000 live births HIV/AIDS (0-4 years)\n",
        "* **GDP**: Gross Domestic Product per capita (in USD)\n",
        "* **Population**: Population of the country\n",
        "* **thinness 1-19 years**: Proportion of thinness among children and adolescents for Age 10 to 19 (in %)\n",
        "* **thinness 5-9 years**: Proportion of thinness among children for Age 5 to 9 (in %)\n",
        "* **Income composition of resources**: Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n",
        "* **Schooling**: Number of years of schooling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a292c91",
      "metadata": {
        "id": "2a292c91"
      },
      "source": [
        "## 1. Understand and Clean the Dataset\n",
        "### 1.1 Initial exploration\n",
        "\n",
        ">1.1.1 Show the first 5 or 10 rows to get an idea of the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57577de4",
      "metadata": {
        "id": "57577de4"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a01a5e0",
      "metadata": {
        "id": "1a01a5e0"
      },
      "source": [
        ">1.1.2 How many observations (rows) and columns are in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e8356c1",
      "metadata": {
        "id": "8e8356c1"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9aa68cca",
      "metadata": {
        "id": "9aa68cca"
      },
      "source": [
        "> 1.1.3 For which variable(s), if any, are there missing/null values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45868696",
      "metadata": {
        "id": "45868696"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffd7b5ff",
      "metadata": {
        "id": "ffd7b5ff"
      },
      "source": [
        ">1.1.4 Apply two small modifications to the names of the columns, that will help you avoid errors. \n",
        "* Remove spaces from beginning and end of the names of the features, if they have some\n",
        "* Put all the feature names start with an uppercase letter or all with a lowercase letter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7476d0a",
      "metadata": {
        "id": "b7476d0a"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c9953be",
      "metadata": {
        "id": "9c9953be"
      },
      "source": [
        ">1.1.5 Drop the following columns (we will not need them):\n",
        "* Adult Mortality\n",
        "* Alcohol\n",
        "* Under-five deaths \n",
        "* Total expenditure\n",
        "* Diphtheria\n",
        "* Thinness  1-19 years\n",
        "* Thinness 5-9 years\n",
        "* Income composition of resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93e2611a",
      "metadata": {
        "id": "93e2611a"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f330e9e4",
      "metadata": {
        "id": "f330e9e4"
      },
      "source": [
        ">1.1.6 Which state had the highest **life expectancy** in a single year? ONLY for this question and the following one (1.1.7), you will need to drop the rows that have NaN as life expectancy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "118edea6",
      "metadata": {
        "id": "118edea6"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97fa7714",
      "metadata": {
        "id": "97fa7714"
      },
      "source": [
        ">1.1.7 Which state had the highest **life expectancy** on average over all the years covered by the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45b40d5",
      "metadata": {
        "id": "c45b40d5"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed658bc8",
      "metadata": {
        "id": "ed658bc8"
      },
      "source": [
        ">1.1.8 What percentage of developing countries have GDP per capita (averaged over the period) higher than 1000? Drop countries with missing GDP for this question. Round up to 3 decimal points. ONLY for this question, you will need to drop the rows that have NaN as GDP.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f091e90",
      "metadata": {
        "id": "9f091e90"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952cf424",
      "metadata": {
        "id": "952cf424"
      },
      "source": [
        "### 1.2 Data types\n",
        "\n",
        ">1.2.1. List the different features and their data type. ¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f22cde4",
      "metadata": {
        "id": "1f22cde4"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce572ee",
      "metadata": {
        "id": "6ce572ee"
      },
      "source": [
        ">1.2.2. Are there any duplicated entries?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5b226c",
      "metadata": {
        "id": "5c5b226c"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b22dd60",
      "metadata": {
        "id": "2b22dd60"
      },
      "source": [
        ">1.2.3. Change the data type for the following columns: Country (from object to string), Status (from object to category)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e576111",
      "metadata": {
        "id": "7e576111"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d9dfea9",
      "metadata": {
        "id": "0d9dfea9"
      },
      "source": [
        ">1.2.4. For which period have these data samples been collected? (i.e, the oldest and the most recent entries in the dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5226461f",
      "metadata": {
        "id": "5226461f"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2077bdc4",
      "metadata": {
        "id": "2077bdc4"
      },
      "source": [
        "\n",
        "## 2. Exploratory Data Analysis and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2401911",
      "metadata": {
        "id": "c2401911"
      },
      "source": [
        ">2.1 Which are the top 5 countries that had the highest **population growth** over the period included in the dataset?\n",
        "Consider population growth as the difference between the population in the last year and the first year of measurement\n",
        "\n",
        ">Hint: for each country, the data follows a certain order..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec50ac9b",
      "metadata": {
        "id": "ec50ac9b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871125ee",
      "metadata": {
        "id": "871125ee"
      },
      "source": [
        ">2.2 How many unique countries were included in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d616dc86",
      "metadata": {
        "id": "d616dc86"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e5d7b18",
      "metadata": {
        "id": "5e5d7b18"
      },
      "source": [
        ">...Plot the top ten countries by average GDP on a horizontal bar chart."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4a6318",
      "metadata": {
        "id": "ed4a6318"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c64c6a56",
      "metadata": {
        "id": "c64c6a56"
      },
      "source": [
        ">2.3. Sometimes it is useful to group datapoints that share certain common traits. That's what we'll do in this composite question. All the modifications to the dataframe suggested here must be ONLY for the questions 2.3. So we suggest to generate a new dataframe for this question, to avoid affecting the main one.\n",
        "\n",
        "> 2.3.1 First, aggregate the data by country taking the mean of every numerical feature. At this point you should have 1 row per Country. Keep only the following features: `HIV/AIDS`,`Polio`,`Measles`,`Infant deaths`,`Hepatitis B`. (Remember, you might need the other features after question 2.3, so do not delete them from the main df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3357125",
      "metadata": {
        "id": "d3357125"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0aedb3b",
      "metadata": {
        "id": "a0aedb3b"
      },
      "source": [
        "> 2.3.2 Then, keep only the following columns, and AFTERWARDS drop all the rows that have NaN values : `HIV/AIDS`,`Polio`,`Measles`,`Infant deaths`,`Hepatitis B`. (Remember, you might need them after question 2.3, so do not delete them from the main df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bedee774",
      "metadata": {
        "id": "bedee774"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c178f5b",
      "metadata": {
        "id": "4c178f5b"
      },
      "source": [
        "> 2.3.3 Then, build a new column in the dataset with a new composite index, the NHI (New Health Index). It integrates the situation of the country with regards to the HIV/AIDS, Polio, Measles, Infant deaths, Hepatitis B. The higher, the worse the situation. It needs to follow the following formula: $$BHI = 10*HIV + 2*Polio + \\sqrt{Measles} + (Infant deaths)^{2} + Hepatitis B$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d49d7e81",
      "metadata": {
        "id": "d49d7e81"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03876467",
      "metadata": {
        "id": "03876467"
      },
      "source": [
        "> 2.3.4 After you added the column with the index, create another column, categorical, called \"Health risk\", which can have 4 different values:\n",
        "* Very high risk\n",
        "* High risk\n",
        "* Medium risk\n",
        "* Low risk\n",
        "> You should assign the value to each row depening on the quartile the datapoint belongs to, following the NHI. If it is in the lowest 25%, it needs to be low risk, if it's between 25 and 50%, it will be Medium, between 50 and 75% High risk, between 75% and 100% Very high risk.\n",
        "Hint: you may want to check the `qcut` function of Pandas.\n",
        "\n",
        "> Finally, count the values of each class you created. How many datapoints are \"High Risk\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662ec22b",
      "metadata": {
        "id": "662ec22b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34bb4080",
      "metadata": {
        "id": "34bb4080"
      },
      "source": [
        ">2.4 Compare GDP in 2002 and in 2012. Were there any countries that had a lower GDP with respect to 2002? If so, how many?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a89547",
      "metadata": {
        "id": "15a89547"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daab9fe9",
      "metadata": {
        "id": "daab9fe9"
      },
      "source": [
        ">2.5 Generate a table with the average life expectancy by year for three different groups: \n",
        ">* for all developing countries\n",
        ">* developed countries\n",
        ">* the overall aggregated values.\n",
        "\n",
        ">Then, plot the three trends in a line plot with the aggregated values for Life expectancy on y axis and the years on the x axis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78e924e2",
      "metadata": {
        "id": "78e924e2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Generate the table\n",
        "\n",
        "\n",
        "# Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "778bfb22",
      "metadata": {
        "id": "778bfb22"
      },
      "source": [
        ">2.6 Draw boxplots to compare the BMI (body mass index) between developed and developing countries. Before doing so, aggregate by country and average over time the BMI for each country. Remember to remove Nans. Do developed or developing have a higher median? Which has more outliers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6126f14d",
      "metadata": {
        "id": "6126f14d"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f0253ef",
      "metadata": {
        "id": "5f0253ef"
      },
      "source": [
        ">2.7 Using `folium`, plot on an interactive map the life expectancy of the countries represented in the dataset. You need to have a scale of colors, the more intense the color, the higher the life expectancy of the country.\n",
        ">\n",
        "> Only include 2015 data.\n",
        ">\n",
        ">A separate geojson file with latitudes and longitudes of the countries needs to be downloaded from [here](https://datahub.io/core/geo-countries). You should use the `folium.Choropleth` method and give the geojson file as `geo_data` parameter. The `key_on` parameter should be set to `\"feature.properties.ADMIN\"` because of the structure of the json file. Make sure to drop any missing values before plotting your map.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02779a11",
      "metadata": {
        "id": "02779a11"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "geo = \"countries.geojson\"\n",
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c37c70",
      "metadata": {
        "id": "f2c37c70"
      },
      "source": [
        "## Before regression: One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "697d3601",
      "metadata": {
        "id": "697d3601"
      },
      "source": [
        "Before moving on to the regression, we need to transform the categorical variables as dummy variables for the regression. In order to do so, we use a [One Hot Encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). Pay attention: we need to consider \"year\" as a categorical variable as well, as it is not a continuous one. So the two features that you need to encode are: Year and Status. Add the features to the dataset. \n",
        "Reminder: when encoding n categories, we need to add n-1 features to avoid multicollinearity - the \"Dummy variable trap\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08213906",
      "metadata": {
        "id": "08213906"
      },
      "source": [
        ">2.8 How many features does the dataframe have now, after adding n-1 columns for year and m-1 for status, where n and m are respectively the number of categories possible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea84e615",
      "metadata": {
        "id": "ea84e615"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66faa2ac",
      "metadata": {
        "id": "66faa2ac"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cddc6205",
      "metadata": {
        "id": "cddc6205"
      },
      "source": [
        "## 3. Regression Analysis\n",
        "### 3.1 Intro to regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733c071c",
      "metadata": {
        "id": "733c071c"
      },
      "source": [
        "For this section we will try to build a model to predict the life expectancy, given other data regarding a country. Here we are providing the cleaned dataframe for you. The regression dataset is the same you've been working on until now with some additional cleaning. The features available are the following:\n",
        "* Alcohol\n",
        "* Schooling\n",
        "* GDP\n",
        "* Life expectancy\n",
        "* Percentage expenditure\n",
        "* One dummy feature for each year except for 1 (2000,2001,2002,...)\n",
        "* One dummy feature \"Developing\" indicating whether the country is a developing one or not"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58296995",
      "metadata": {
        "id": "58296995"
      },
      "source": [
        ">Load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee725745",
      "metadata": {
        "id": "ee725745"
      },
      "outputs": [],
      "source": [
        "#Upload the data\n",
        "new_data = pd.read_csv(\"Regression Analysis Data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23b94d68",
      "metadata": {
        "id": "23b94d68"
      },
      "source": [
        ">3.1.1. Generate descriptive statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc64839",
      "metadata": {
        "id": "3dc64839"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cffa904b",
      "metadata": {
        "id": "cffa904b"
      },
      "source": [
        ">3.1.2. Plot the distribution of life expectancy in 2000 and in 2012. Then create a new column equal to the natural logarithm of life expectancy and plot its histogram as well, just for year 2000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd095c90",
      "metadata": {
        "id": "cd095c90"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "#Generate the first 2 histograms: 2000 and 2012\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0c4359b",
      "metadata": {
        "id": "b0c4359b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "#Add the new column with the log\n",
        "\n",
        "#Generate the second histogram: 2000, but with the log\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de453534",
      "metadata": {
        "id": "de453534"
      },
      "source": [
        ">3.1.3. Create 3 pairplots with the log of life expectancy on the horizontal axis and on the vertical axis GDP, population, schooling. Which seems to be the best predictor?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791c3f2b",
      "metadata": {
        "id": "791c3f2b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e59b86",
      "metadata": {
        "id": "26e59b86"
      },
      "source": [
        "## 3.2 Simple Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beb92990",
      "metadata": {
        "id": "beb92990"
      },
      "source": [
        ">3.2.1 Drop the feature \"Year\", since we have hot-encoded it. Regress, using the library `sklearn`, log of life expectancy on Alcohol, gdp, population, percentage expenditure, schooling, Developing, and all the dummy variables for the years.\n",
        "> \n",
        ">Select the dependent (y) and the independent variables (X)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66ac250",
      "metadata": {
        "id": "a66ac250"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0fcc79d",
      "metadata": {
        "id": "f0fcc79d"
      },
      "source": [
        ">3.2.2 Split your dataset into a training set (80%) and a test set (20%). Use sklearn.model_selection.train_test_split() and set the **random_state to 42.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ab982a",
      "metadata": {
        "id": "a9ab982a"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32987cf8",
      "metadata": {
        "id": "32987cf8"
      },
      "source": [
        ">3.2.3 Train a linear regression model on the training data. What is the R^2 score for the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba053d77",
      "metadata": {
        "id": "ba053d77"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33aae726",
      "metadata": {
        "id": "33aae726"
      },
      "source": [
        ">3.2.4. Predict what would be the life expectancy of a (very small) country with an Alcohol consumption of 5 liters, GDP per capita of 800 dollars, a population of 300 individuals, 62 as percentage expenditure, 8 as schooling in year 2000. It is not a developing country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5fda51",
      "metadata": {
        "id": "9e5fda51"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed88806",
      "metadata": {
        "id": "0ed88806"
      },
      "source": [
        "## 3.3 Linear Regression with Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ed3ea98",
      "metadata": {
        "id": "0ed3ea98"
      },
      "source": [
        "> 3.3.1. Apply a standard scaler to the following columns: Alcohol, gdp, population, percentage expenditure, schooling\n",
        "> \n",
        "> Hint: use the scaler on the already split data. Fit-transform the scaler on X_train and apply transform on X_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cac99fa4",
      "metadata": {
        "id": "cac99fa4"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb211204",
      "metadata": {
        "id": "eb211204"
      },
      "source": [
        "> 3.3.2 Train a linear regression model with the standardised data. What is the R^2 score for the test data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef7cbfd",
      "metadata": {
        "id": "bef7cbfd"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae1b9d5",
      "metadata": {
        "id": "7ae1b9d5"
      },
      "source": [
        "> 3.3.3 With the new model, predict, as before, what would be the life expectancy of a (very small) country with an Alcohol consumption of 5 liters, GDP per capita of 800 dollars, a population of 300 individuals, 62 as percentage expenditure, 8 as schooling in year 2000. It is not a developing country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71804228",
      "metadata": {
        "id": "71804228"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d921b338",
      "metadata": {
        "id": "d921b338"
      },
      "source": [
        ">3.3.4 Looking at the coefficients from the linear regression with standardization, identify which variable is the one with the strongest impact on the dependent variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bd6a35",
      "metadata": {
        "id": "24bd6a35"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3ee367e",
      "metadata": {
        "id": "a3ee367e"
      },
      "source": [
        "> 3.3.5 Calculate the adjusted R-squared and identify the optimum regression coefficients using linear regression with standardisation. \n",
        ">\n",
        "> Hint: calculate the adjusted R-squared for the full model with linear regression and standardisation (as above). The try dropping either one of the columns: `GDP`, `Population` and all the year features and recalculate adjusted R-squared for every new model. Identify which combination of features gives the highest adjusted R-squared. \n",
        ">\n",
        ">Check out this documentation file on the [adjusted R-squared](https://www.statology.org/adjusted-r-squared-in-python/).\n",
        ">\n",
        "> Remember to use 42 as the **random_state**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3de67a1",
      "metadata": {
        "id": "e3de67a1"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aae8c757",
      "metadata": {
        "id": "aae8c757"
      },
      "source": [
        ">3.3.6 Train the model when you drop `GDP` and calculate the adjusted R-squared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1557cf4b",
      "metadata": {
        "id": "1557cf4b"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a82f734",
      "metadata": {
        "id": "7a82f734"
      },
      "source": [
        "> 3.3.7 Train the model when you drop `Population` and calculate the adjusted R-squared. Pay attention: you only need to drop `Population`, you need `GDP` back in there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c6e10f",
      "metadata": {
        "id": "51c6e10f"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "332e6b7e",
      "metadata": {
        "id": "332e6b7e"
      },
      "source": [
        ">3.3.8 Train the model when you drop all the year features and calculate the adjusted R-squared. Pay attention: you only need to drop all the year features, you need `GDP` and `Population` back in there. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552b76da",
      "metadata": {
        "id": "552b76da"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "288px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}