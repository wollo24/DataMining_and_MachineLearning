{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataMining_and_MachineLearning/blob/master/week11/Pytorch_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "qrYKRqsUVZNK"
      },
      "id": "qrYKRqsUVZNK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fleet-potter"
      },
      "source": [
        "# Predicting house prices with neural networks"
      ],
      "id": "fleet-potter"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "sunset-blast"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "sunset-blast"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "likely-interaction"
      },
      "source": [
        "## Data"
      ],
      "id": "likely-interaction"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruled-spider"
      },
      "source": [
        "### loading the data"
      ],
      "id": "ruled-spider"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "grave-snake",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "9a5189cf-eeef-42d2-fb2b-ba8aa6292dc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
              "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
              "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
              "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
              "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
              "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
              "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
              "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
              "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
              "\n",
              "  YrSold  SaleType  SaleCondition  SalePrice  \n",
              "0   2008        WD         Normal     208500  \n",
              "1   2007        WD         Normal     181500  \n",
              "2   2008        WD         Normal     223500  \n",
              "3   2006        WD        Abnorml     140000  \n",
              "4   2008        WD         Normal     250000  \n",
              "\n",
              "[5 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b194ec4-9699-4d2d-8dad-57ec87d110e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>70</td>\n",
              "      <td>RL</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>WD</td>\n",
              "      <td>Abnorml</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b194ec4-9699-4d2d-8dad-57ec87d110e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b194ec4-9699-4d2d-8dad-57ec87d110e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b194ec4-9699-4d2d-8dad-57ec87d110e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "raw_data = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/week11/data/housing_dataset.csv\")\n",
        "raw_data.head()"
      ],
      "id": "grave-snake"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "adjacent-substance",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa58c7f-a9ee-49a1-875e-5fda05796e5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 81)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "raw_data.shape"
      ],
      "id": "adjacent-substance"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "annual-officer"
      },
      "source": [
        "### Extracting the numeric columns"
      ],
      "id": "annual-officer"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "identified-wildlife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "994c65ad-b770-4ad7-e454-c6ab37b37c86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                 int64\n",
              "MSSubClass         int64\n",
              "MSZoning          object\n",
              "LotFrontage      float64\n",
              "LotArea            int64\n",
              "                  ...   \n",
              "MoSold             int64\n",
              "YrSold             int64\n",
              "SaleType          object\n",
              "SaleCondition     object\n",
              "SalePrice          int64\n",
              "Length: 81, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "raw_data.dtypes"
      ],
      "id": "identified-wildlife"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "rubber-corrections",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47e7f30-af76-461d-84a0-97b45464e309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice'] \n",
            " 38\n"
          ]
        }
      ],
      "source": [
        "numeric_columns = list(raw_data.columns[(raw_data.dtypes==np.int64) |\n",
        "                 (raw_data.dtypes==np.float64)])\n",
        "print(numeric_columns, \"\\n\", len(numeric_columns))"
      ],
      "id": "rubber-corrections"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "announced-incidence"
      },
      "source": [
        "Set `SalesPrice` as the last index, since it is the value we want to predict."
      ],
      "id": "announced-incidence"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "intermediate-cable"
      },
      "outputs": [],
      "source": [
        "numeric_columns.remove('SalePrice')\n",
        "numeric_columns.append('SalePrice')"
      ],
      "id": "intermediate-cable"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "extended-attribute"
      },
      "source": [
        "We do not need the `Id` column."
      ],
      "id": "extended-attribute"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "marked-cancellation"
      },
      "outputs": [],
      "source": [
        "numeric_columns.remove('Id')"
      ],
      "id": "marked-cancellation"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "returning-vertex"
      },
      "source": [
        "Now we extract the numeric data."
      ],
      "id": "returning-vertex"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "irish-probe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "ced2fdd9-3481-4670-cde0-0acd79e78b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
              "0          60         65.0     8450            7            5       2003   \n",
              "1          20         80.0     9600            6            8       1976   \n",
              "2          60         68.0    11250            7            5       2001   \n",
              "3          70         60.0     9550            7            5       1915   \n",
              "4          60         84.0    14260            8            5       2000   \n",
              "\n",
              "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
              "0          2003       196.0         706           0  ...           0   \n",
              "1          1976         0.0         978           0  ...         298   \n",
              "2          2002       162.0         486           0  ...           0   \n",
              "3          1970         0.0         216           0  ...           0   \n",
              "4          2000       350.0         655           0  ...         192   \n",
              "\n",
              "   OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
              "0           61              0          0            0         0        0   \n",
              "1            0              0          0            0         0        0   \n",
              "2           42              0          0            0         0        0   \n",
              "3           35            272          0            0         0        0   \n",
              "4           84              0          0            0         0        0   \n",
              "\n",
              "   MoSold  YrSold  SalePrice  \n",
              "0       2    2008     208500  \n",
              "1       5    2007     181500  \n",
              "2       9    2008     223500  \n",
              "3       2    2006     140000  \n",
              "4      12    2008     250000  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-847f68c3-cd2e-4f4b-8cec-0311faa8945d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinSF2</th>\n",
              "      <th>...</th>\n",
              "      <th>WoodDeckSF</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>EnclosedPorch</th>\n",
              "      <th>3SsnPorch</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>65.0</td>\n",
              "      <td>8450</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>196.0</td>\n",
              "      <td>706</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>80.0</td>\n",
              "      <td>9600</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>298</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2007</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>11250</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>162.0</td>\n",
              "      <td>486</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>2008</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>70</td>\n",
              "      <td>60.0</td>\n",
              "      <td>9550</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60</td>\n",
              "      <td>84.0</td>\n",
              "      <td>14260</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>350.0</td>\n",
              "      <td>655</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>2008</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-847f68c3-cd2e-4f4b-8cec-0311faa8945d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-847f68c3-cd2e-4f4b-8cec-0311faa8945d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-847f68c3-cd2e-4f4b-8cec-0311faa8945d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "numeric_data = raw_data[numeric_columns]\n",
        "numeric_data.head()"
      ],
      "id": "irish-probe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "warming-cartoon"
      },
      "source": [
        "Now let's deal with the missing values in the data."
      ],
      "id": "warming-cartoon"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "obvious-rider",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b01a2e-3a8b-4829-ce45-aca016c8f1dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "nan_columns = np.any(pd.isna(numeric_data), axis = 0)\n",
        "nan_columns = list(nan_columns[nan_columns == True].index)\n",
        "nan_columns"
      ],
      "id": "obvious-rider"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "activated-center"
      },
      "source": [
        "We simply replace them with zero."
      ],
      "id": "activated-center"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "quarterly-murray",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55dbceb6-bb69-45ff-ef1c-a16e9a20bde5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "numeric_data['LotFrontage'] = numeric_data['LotFrontage'].fillna(0)\n",
        "numeric_data['MasVnrArea'] = numeric_data['MasVnrArea'].fillna(0)\n",
        "numeric_data['GarageYrBlt'] = numeric_data['GarageYrBlt'].fillna(0)"
      ],
      "id": "quarterly-murray"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joined-grade"
      },
      "source": [
        "let's split the data for training and test!"
      ],
      "id": "joined-grade"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "northern-welsh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "numeric_data_train, numeric_data_test = train_test_split(numeric_data, test_size=0.1)"
      ],
      "id": "northern-welsh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "automatic-candy"
      },
      "source": [
        "### Normalizing the data\n",
        "Before training our linear regression model, we have to normalize the data. We do this by subtracting each column from its minimum value and then dividing it by the difference between maximum and minimum."
      ],
      "id": "automatic-candy"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "dominant-thanksgiving"
      },
      "outputs": [],
      "source": [
        "# saving max, min for each column\n",
        "maxs, mins = dict(), dict()"
      ],
      "id": "dominant-thanksgiving"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "pursuant-class"
      },
      "outputs": [],
      "source": [
        "for col in numeric_data:\n",
        "    maxs[col] = numeric_data_train[col].max()\n",
        "    mins[col] = numeric_data_train[col].min()"
      ],
      "id": "pursuant-class"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "resistant-bathroom"
      },
      "outputs": [],
      "source": [
        "numeric_data_train = (numeric_data_train - numeric_data_train.min()) / (numeric_data_train.max() - numeric_data_train.min())"
      ],
      "id": "resistant-bathroom"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sensitive-notion"
      },
      "source": [
        "## Building a Linear Regression model"
      ],
      "id": "sensitive-notion"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "insured-reviewer"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "id": "insured-reviewer"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "perfect-promise"
      },
      "outputs": [],
      "source": [
        "numeric_x_columns = list(numeric_data_train.columns)\n",
        "numeric_x_columns.remove(\"SalePrice\")\n",
        "X_train_df = numeric_data_train[numeric_x_columns]\n",
        "y_train_df = pd.DataFrame(numeric_data_train[\"SalePrice\"])"
      ],
      "id": "perfect-promise"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wanted-surge"
      },
      "source": [
        "Now we have to convert the data into torch tensors. A `torch.Tensor` is a multi-dimensional matrix containing elements of a single data type. It's very similar to arrays in `NumPy`."
      ],
      "id": "wanted-surge"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "ranging-hudson"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor(X_train_df.values, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_df.values, dtype=torch.float)"
      ],
      "id": "ranging-hudson"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "prescribed-reason",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2efed21-2d16-476b-f12a-6660255eef3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1314, 36]) torch.Size([1314, 1])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.size(), y_train.size())"
      ],
      "id": "prescribed-reason"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baking-jamaica"
      },
      "source": [
        "### Defining a model with pytorch\n",
        "A model is always defined as a class in pytorch. It should have a `__init__` function in which you define the layers of your network. It also should have a `forward` function (method) that basically defines the forward pass on the network.\n",
        "\n",
        "For the beggining, let's start with a single layer network."
      ],
      "id": "baking-jamaica"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "written-motel"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, D_in, H1, D_out):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))\n",
        "        y_pred = self.linear2(y_pred)\n",
        "        return y_pred"
      ],
      "id": "written-motel"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "sustainable-blade"
      },
      "outputs": [],
      "source": [
        "D_in, D_out = X_train.shape[1], y_train.shape[1]"
      ],
      "id": "sustainable-blade"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "subjective-camcorder"
      },
      "outputs": [],
      "source": [
        "# defining the first model: an instance of the class \"Net\"\n",
        "model1 = Net(D_in, 500, D_out)"
      ],
      "id": "subjective-camcorder"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sticky-flash"
      },
      "source": [
        "The next steps is to define the __loss criterion__ and the __optimizer__ for the network. That is, we have to define the loss function we want to optimize during training and also the optimization method we are going to use, e.g, SGD, etc."
      ],
      "id": "sticky-flash"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "permanent-fancy"
      },
      "outputs": [],
      "source": [
        "# MSE loss\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "# SGD optimizer for finding the weights of the network\n",
        "optimizer = torch.optim.SGD(model1.parameters(), lr=1e-4)"
      ],
      "id": "permanent-fancy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "individual-gentleman"
      },
      "source": [
        "Now, we are ready to do the training. We can simply do this by a for loop over the number of iterations. The training has 3 main steps:\n",
        "- A forward pass to compute the prediction for the current data point (batch).\n",
        "- computing the loss for the current prediction.\n",
        "- A backward pass to compute the gradient of the loss with respect to the weight of the network.\n",
        "- Finaly, updating the weights of the network (`optimizer.step()`).\n",
        "\n",
        "Note that in each backward pass pytorch saves the gradient for all of the parameters. Therefore it is important to replace the old gradient values with zero in the beggining of each iteration, otherwise the gradients will be accumulated during the iterations!"
      ],
      "id": "individual-gentleman"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "JT_JOfiXhz6W"
      },
      "outputs": [],
      "source": [
        "# we need to normalize the test data with the min and max value\n",
        "# from the training data\n",
        "for col in numeric_data_test.columns:\n",
        "    numeric_data_test[col] = (numeric_data_test[col] - mins[col]) / (maxs[col] - mins[col])"
      ],
      "id": "JT_JOfiXhz6W"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ISuJYYwkgsbI"
      },
      "outputs": [],
      "source": [
        "# normalize the test data \n",
        "y_test_df = pd.DataFrame(numeric_data_test[\"SalePrice\"])\n",
        "y_test = torch.tensor(y_test_df.values, dtype=torch.float)\n",
        "x_test_df = numeric_data_test[numeric_x_columns]\n",
        "x_test = torch.tensor(x_test_df.values, dtype=torch.float)"
      ],
      "id": "ISuJYYwkgsbI"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "earlier-maximum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef2f40b-7a7c-463a-d8d4-5ae823dd8012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 130.5743408203125\n",
            "1 1294.43505859375\n",
            "2 11896.84765625\n",
            "3 6695.265625\n",
            "4 43.54777908325195\n",
            "5 32.55015182495117\n",
            "6 26.683879852294922\n",
            "7 23.50665283203125\n",
            "8 21.738168716430664\n",
            "9 20.708471298217773\n",
            "10 20.066730499267578\n",
            "11 19.629928588867188\n",
            "12 19.30201530456543\n",
            "13 19.03306770324707\n",
            "14 18.79705810546875\n",
            "15 18.579790115356445\n",
            "16 18.373620986938477\n",
            "17 18.17457389831543\n",
            "18 17.98070526123047\n",
            "19 17.791189193725586\n",
            "20 17.605419158935547\n",
            "21 17.422754287719727\n",
            "22 17.242847442626953\n",
            "23 17.06535530090332\n",
            "24 16.890451431274414\n",
            "25 16.717634201049805\n",
            "26 16.546937942504883\n",
            "27 16.378273010253906\n",
            "28 16.211536407470703\n",
            "29 16.046537399291992\n",
            "30 15.883082389831543\n",
            "31 15.721307754516602\n",
            "32 15.560848236083984\n",
            "33 15.402021408081055\n",
            "34 15.244546890258789\n",
            "35 15.088231086730957\n",
            "36 14.93294906616211\n",
            "37 14.778922080993652\n",
            "38 14.625255584716797\n",
            "39 14.47214126586914\n",
            "40 14.319780349731445\n",
            "41 14.167791366577148\n",
            "42 14.016284942626953\n",
            "43 13.8654203414917\n",
            "44 13.714788436889648\n",
            "45 13.564779281616211\n",
            "46 13.415143013000488\n",
            "47 13.265595436096191\n",
            "48 13.116497039794922\n",
            "49 12.967984199523926\n",
            "50 12.819866180419922\n",
            "51 12.672199249267578\n",
            "52 12.525372505187988\n",
            "53 12.378893852233887\n",
            "54 12.232177734375\n",
            "55 12.085726737976074\n",
            "56 11.939604759216309\n",
            "57 11.793960571289062\n",
            "58 11.648094177246094\n",
            "59 11.50270938873291\n",
            "60 11.357428550720215\n",
            "61 11.212872505187988\n",
            "62 11.06837272644043\n",
            "63 10.924077987670898\n",
            "64 10.779438972473145\n",
            "65 10.63558578491211\n",
            "66 10.492424964904785\n",
            "67 10.349710464477539\n",
            "68 10.20751953125\n",
            "69 10.06595230102539\n",
            "70 9.925274848937988\n",
            "71 9.785345077514648\n",
            "72 9.646661758422852\n",
            "73 9.509325981140137\n",
            "74 9.373480796813965\n",
            "75 9.239212036132812\n",
            "76 9.1058931350708\n",
            "77 8.974267959594727\n",
            "78 8.843998908996582\n",
            "79 8.716009140014648\n",
            "80 8.589936256408691\n",
            "81 8.46518611907959\n",
            "82 8.342020034790039\n",
            "83 8.220935821533203\n",
            "84 8.102046012878418\n",
            "85 7.984983444213867\n",
            "86 7.869533538818359\n",
            "87 7.756435394287109\n",
            "88 7.645452976226807\n",
            "89 7.536914825439453\n",
            "90 7.430627822875977\n",
            "91 7.3264946937561035\n",
            "92 7.22477388381958\n",
            "93 7.125422477722168\n",
            "94 7.028358459472656\n",
            "95 6.934027194976807\n",
            "96 6.842447280883789\n",
            "97 6.7537078857421875\n",
            "98 6.667624473571777\n",
            "99 6.584219932556152\n",
            "100 6.503366470336914\n",
            "101 6.424792289733887\n",
            "102 6.348666191101074\n",
            "103 6.274768829345703\n",
            "104 6.2029266357421875\n",
            "105 6.133363723754883\n",
            "106 6.06619930267334\n",
            "107 6.001182556152344\n",
            "108 5.938448905944824\n",
            "109 5.877753734588623\n",
            "110 5.819062232971191\n",
            "111 5.7623443603515625\n",
            "112 5.707569122314453\n",
            "113 5.654819011688232\n",
            "114 5.603885650634766\n",
            "115 5.554784774780273\n",
            "116 5.507512092590332\n",
            "117 5.461930274963379\n",
            "118 5.418073654174805\n",
            "119 5.375828742980957\n",
            "120 5.33509635925293\n",
            "121 5.295774459838867\n",
            "122 5.257876396179199\n",
            "123 5.221244812011719\n",
            "124 5.185888767242432\n",
            "125 5.151834487915039\n",
            "126 5.11898136138916\n",
            "127 5.087353706359863\n",
            "128 5.056877613067627\n",
            "129 5.027457237243652\n",
            "130 4.999062538146973\n",
            "131 4.971697807312012\n",
            "132 4.945279598236084\n",
            "133 4.919792652130127\n",
            "134 4.895227432250977\n",
            "135 4.871554374694824\n",
            "136 4.848702907562256\n",
            "137 4.826603412628174\n",
            "138 4.8052449226379395\n",
            "139 4.784494400024414\n",
            "140 4.764389991760254\n",
            "141 4.744884490966797\n",
            "142 4.725915908813477\n",
            "143 4.707508087158203\n",
            "144 4.689696311950684\n",
            "145 4.6724114418029785\n",
            "146 4.655673980712891\n",
            "147 4.639486789703369\n",
            "148 4.623806953430176\n",
            "149 4.608581066131592\n",
            "150 4.593808174133301\n",
            "151 4.579441547393799\n",
            "152 4.565481662750244\n",
            "153 4.551909446716309\n",
            "154 4.538693428039551\n",
            "155 4.525815963745117\n",
            "156 4.513282299041748\n",
            "157 4.5010762214660645\n",
            "158 4.489190101623535\n",
            "159 4.477620601654053\n",
            "160 4.466317176818848\n",
            "161 4.455286979675293\n",
            "162 4.44449520111084\n",
            "163 4.433941841125488\n",
            "164 4.423604965209961\n",
            "165 4.4134674072265625\n",
            "166 4.403534889221191\n",
            "167 4.39381217956543\n",
            "168 4.384274005889893\n",
            "169 4.374920845031738\n",
            "170 4.36572790145874\n",
            "171 4.356680870056152\n",
            "172 4.347772598266602\n",
            "173 4.339010238647461\n",
            "174 4.330394268035889\n",
            "175 4.321909427642822\n",
            "176 4.313576698303223\n",
            "177 4.305364608764648\n",
            "178 4.2972846031188965\n",
            "179 4.289318084716797\n",
            "180 4.281476020812988\n",
            "181 4.273752689361572\n",
            "182 4.266129493713379\n",
            "183 4.258613109588623\n",
            "184 4.251193046569824\n",
            "185 4.243889808654785\n",
            "186 4.236678600311279\n",
            "187 4.229554653167725\n",
            "188 4.222531795501709\n",
            "189 4.215595245361328\n",
            "190 4.208748817443848\n",
            "191 4.201979160308838\n",
            "192 4.195291996002197\n",
            "193 4.188669681549072\n",
            "194 4.182110786437988\n",
            "195 4.175623416900635\n",
            "196 4.169211387634277\n",
            "197 4.162882328033447\n",
            "198 4.156631946563721\n",
            "199 4.1504387855529785\n",
            "200 4.14431095123291\n",
            "201 4.138252258300781\n",
            "202 4.132246971130371\n",
            "203 4.126298427581787\n",
            "204 4.120418071746826\n",
            "205 4.114610195159912\n",
            "206 4.108846187591553\n",
            "207 4.10313081741333\n",
            "208 4.097469329833984\n",
            "209 4.091838836669922\n",
            "210 4.0862579345703125\n",
            "211 4.080722808837891\n",
            "212 4.075249195098877\n",
            "213 4.069820880889893\n",
            "214 4.064435005187988\n",
            "215 4.059080600738525\n",
            "216 4.053760051727295\n",
            "217 4.048475742340088\n",
            "218 4.04323673248291\n",
            "219 4.03803014755249\n",
            "220 4.032857894897461\n",
            "221 4.027727127075195\n",
            "222 4.022637367248535\n",
            "223 4.017582416534424\n",
            "224 4.012561321258545\n",
            "225 4.007571220397949\n",
            "226 4.002590179443359\n",
            "227 3.9976179599761963\n",
            "228 3.9926626682281494\n",
            "229 3.9877498149871826\n",
            "230 3.982862949371338\n",
            "231 3.9780144691467285\n",
            "232 3.9731955528259277\n",
            "233 3.9684133529663086\n",
            "234 3.9636547565460205\n",
            "235 3.958939790725708\n",
            "236 3.9542527198791504\n",
            "237 3.9495863914489746\n",
            "238 3.9449450969696045\n",
            "239 3.9403257369995117\n",
            "240 3.9357340335845947\n",
            "241 3.9311509132385254\n",
            "242 3.926593780517578\n",
            "243 3.9220590591430664\n",
            "244 3.917548418045044\n",
            "245 3.9130544662475586\n",
            "246 3.9085915088653564\n",
            "247 3.904155969619751\n",
            "248 3.899752616882324\n",
            "249 3.895381212234497\n",
            "250 3.8910295963287354\n",
            "251 3.8866920471191406\n",
            "252 3.882378339767456\n",
            "253 3.878085136413574\n",
            "254 3.873809337615967\n",
            "255 3.8695640563964844\n",
            "256 3.8653337955474854\n",
            "257 3.861131429672241\n",
            "258 3.856945037841797\n",
            "259 3.8527798652648926\n",
            "260 3.848630905151367\n",
            "261 3.8445043563842773\n",
            "262 3.84041166305542\n",
            "263 3.8363213539123535\n",
            "264 3.832253932952881\n",
            "265 3.828212022781372\n",
            "266 3.8241968154907227\n",
            "267 3.8201956748962402\n",
            "268 3.8162362575531006\n",
            "269 3.812300443649292\n",
            "270 3.808375358581543\n",
            "271 3.804459571838379\n",
            "272 3.8005685806274414\n",
            "273 3.796687126159668\n",
            "274 3.7928171157836914\n",
            "275 3.7889764308929443\n",
            "276 3.7851498126983643\n",
            "277 3.7813358306884766\n",
            "278 3.777536630630493\n",
            "279 3.773773670196533\n",
            "280 3.770021915435791\n",
            "281 3.7662839889526367\n",
            "282 3.7625887393951416\n",
            "283 3.7589004039764404\n",
            "284 3.7552366256713867\n",
            "285 3.7515883445739746\n",
            "286 3.747952461242676\n",
            "287 3.744332790374756\n",
            "288 3.740708351135254\n",
            "289 3.73709774017334\n",
            "290 3.7335164546966553\n",
            "291 3.7299437522888184\n",
            "292 3.726397752761841\n",
            "293 3.722869873046875\n",
            "294 3.719346046447754\n",
            "295 3.715850830078125\n",
            "296 3.7123546600341797\n",
            "297 3.7088730335235596\n",
            "298 3.705410957336426\n",
            "299 3.701948642730713\n",
            "300 3.698518991470337\n",
            "301 3.6950907707214355\n",
            "302 3.6916863918304443\n",
            "303 3.6882972717285156\n",
            "304 3.6849122047424316\n",
            "305 3.6815621852874756\n",
            "306 3.6782007217407227\n",
            "307 3.674865484237671\n",
            "308 3.671541213989258\n",
            "309 3.6682214736938477\n",
            "310 3.664944648742676\n",
            "311 3.6616644859313965\n",
            "312 3.6584112644195557\n",
            "313 3.655174732208252\n",
            "314 3.651945114135742\n",
            "315 3.648746967315674\n",
            "316 3.6455435752868652\n",
            "317 3.6423604488372803\n",
            "318 3.639190435409546\n",
            "319 3.636026382446289\n",
            "320 3.6328940391540527\n",
            "321 3.629756212234497\n",
            "322 3.626645088195801\n",
            "323 3.623546838760376\n",
            "324 3.6204497814178467\n",
            "325 3.617377758026123\n",
            "326 3.6143012046813965\n",
            "327 3.6112489700317383\n",
            "328 3.6082072257995605\n",
            "329 3.6051723957061768\n",
            "330 3.6021649837493896\n",
            "331 3.599163055419922\n",
            "332 3.596189498901367\n",
            "333 3.593230724334717\n",
            "334 3.5902822017669678\n",
            "335 3.5873613357543945\n",
            "336 3.5844318866729736\n",
            "337 3.581521511077881\n",
            "338 3.578625440597534\n",
            "339 3.5757365226745605\n",
            "340 3.572868824005127\n",
            "341 3.569993495941162\n",
            "342 3.5671355724334717\n",
            "343 3.564286231994629\n",
            "344 3.5614430904388428\n",
            "345 3.5586187839508057\n",
            "346 3.555779457092285\n",
            "347 3.55295991897583\n",
            "348 3.5501482486724854\n",
            "349 3.5473437309265137\n",
            "350 3.5445642471313477\n",
            "351 3.5417773723602295\n",
            "352 3.5390262603759766\n",
            "353 3.5362603664398193\n",
            "354 3.533515453338623\n",
            "355 3.530773639678955\n",
            "356 3.5280537605285645\n",
            "357 3.5253477096557617\n",
            "358 3.522639036178589\n",
            "359 3.519943952560425\n",
            "360 3.5172410011291504\n",
            "361 3.514561176300049\n",
            "362 3.5118885040283203\n",
            "363 3.509242534637451\n",
            "364 3.506578207015991\n",
            "365 3.503943920135498\n",
            "366 3.5013186931610107\n",
            "367 3.4987001419067383\n",
            "368 3.4960885047912598\n",
            "369 3.493478298187256\n",
            "370 3.490891456604004\n",
            "371 3.488302230834961\n",
            "372 3.4857375621795654\n",
            "373 3.4831721782684326\n",
            "374 3.4806222915649414\n",
            "375 3.478066921234131\n",
            "376 3.4755239486694336\n",
            "377 3.4729785919189453\n",
            "378 3.470461845397949\n",
            "379 3.4679341316223145\n",
            "380 3.4654438495635986\n",
            "381 3.462937355041504\n",
            "382 3.460453748703003\n",
            "383 3.4579720497131348\n",
            "384 3.455521583557129\n",
            "385 3.453061103820801\n",
            "386 3.450631856918335\n",
            "387 3.448185920715332\n",
            "388 3.4457759857177734\n",
            "389 3.4433536529541016\n",
            "390 3.4409589767456055\n",
            "391 3.438563346862793\n",
            "392 3.436187744140625\n",
            "393 3.433807849884033\n",
            "394 3.431443691253662\n",
            "395 3.429070234298706\n",
            "396 3.426720380783081\n",
            "397 3.424359083175659\n",
            "398 3.4220166206359863\n",
            "399 3.419647693634033\n",
            "400 3.4173130989074707\n",
            "401 3.4149627685546875\n",
            "402 3.412639856338501\n",
            "403 3.410292625427246\n",
            "404 3.4079737663269043\n",
            "405 3.4056460857391357\n",
            "406 3.4033384323120117\n",
            "407 3.4010205268859863\n",
            "408 3.398709774017334\n",
            "409 3.3964052200317383\n",
            "410 3.3941102027893066\n",
            "411 3.3918285369873047\n",
            "412 3.3895530700683594\n",
            "413 3.3872885704040527\n",
            "414 3.3850245475769043\n",
            "415 3.3827919960021973\n",
            "416 3.3805465698242188\n",
            "417 3.3783035278320312\n",
            "418 3.3760745525360107\n",
            "419 3.3738455772399902\n",
            "420 3.371641159057617\n",
            "421 3.36942195892334\n",
            "422 3.3672337532043457\n",
            "423 3.365039348602295\n",
            "424 3.362859010696411\n",
            "425 3.3606855869293213\n",
            "426 3.358513355255127\n",
            "427 3.356361150741577\n",
            "428 3.354212522506714\n",
            "429 3.3520750999450684\n",
            "430 3.349940061569214\n",
            "431 3.3478147983551025\n",
            "432 3.3456993103027344\n",
            "433 3.343587636947632\n",
            "434 3.3414928913116455\n",
            "435 3.339385509490967\n",
            "436 3.337306499481201\n",
            "437 3.335218667984009\n",
            "438 3.3331527709960938\n",
            "439 3.3310952186584473\n",
            "440 3.3290445804595947\n",
            "441 3.327007293701172\n",
            "442 3.3249645233154297\n",
            "443 3.3229353427886963\n",
            "444 3.320895195007324\n",
            "445 3.3188679218292236\n",
            "446 3.316843032836914\n",
            "447 3.314821720123291\n",
            "448 3.312812566757202\n",
            "449 3.310791015625\n",
            "450 3.3087844848632812\n",
            "451 3.3067710399627686\n",
            "452 3.3047714233398438\n",
            "453 3.302757740020752\n",
            "454 3.3007586002349854\n",
            "455 3.298765182495117\n",
            "456 3.2967777252197266\n",
            "457 3.2948031425476074\n",
            "458 3.2928261756896973\n",
            "459 3.2908759117126465\n",
            "460 3.2889161109924316\n",
            "461 3.2869791984558105\n",
            "462 3.2850308418273926\n",
            "463 3.2831075191497803\n",
            "464 3.281179189682007\n",
            "465 3.2792623043060303\n",
            "466 3.277348756790161\n",
            "467 3.2754316329956055\n",
            "468 3.273524761199951\n",
            "469 3.2716150283813477\n",
            "470 3.2697229385375977\n",
            "471 3.267825126647949\n",
            "472 3.2659354209899902\n",
            "473 3.2640531063079834\n",
            "474 3.2621662616729736\n",
            "475 3.2602906227111816\n",
            "476 3.258409023284912\n",
            "477 3.256547451019287\n",
            "478 3.2546775341033936\n",
            "479 3.2528300285339355\n",
            "480 3.2509658336639404\n",
            "481 3.24912691116333\n",
            "482 3.2472686767578125\n",
            "483 3.245431900024414\n",
            "484 3.2435810565948486\n",
            "485 3.241746425628662\n",
            "486 3.2399086952209473\n",
            "487 3.2380850315093994\n",
            "488 3.2362594604492188\n",
            "489 3.2344393730163574\n",
            "490 3.2326300144195557\n",
            "491 3.230815887451172\n",
            "492 3.229015350341797\n",
            "493 3.227203845977783\n",
            "494 3.2254011631011963\n",
            "495 3.223586082458496\n",
            "496 3.2217841148376465\n",
            "497 3.219974994659424\n",
            "498 3.218165397644043\n",
            "499 3.216365337371826\n"
          ]
        }
      ],
      "source": [
        "losses1 = []\n",
        "losses1_test = []\n",
        "for t in range(500):\n",
        "    y_pred = model1(X_train)\n",
        "    \n",
        "    loss = criterion(y_pred, y_train)\n",
        "    print(t, loss.item())\n",
        "    losses1.append(loss.item())\n",
        "    \n",
        "    if torch.isnan(loss):\n",
        "        break\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # test loss\n",
        "    losses1_test.append(criterion(model1(x_test), y_test).item())"
      ],
      "id": "earlier-maximum"
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "KG4HrZFfhXZs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "5307bee8-4b36-42db-8a48-34efa5667a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff0d2ccc510>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(losses1, label=\"training loss\")\n",
        "plt.plot(losses1_test, label=\"test_loss\")\n",
        "plt.ylim(top=70, bottom=0.0)\n",
        "plt.legend()"
      ],
      "id": "KG4HrZFfhXZs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coordinated-mexican"
      },
      "source": [
        "Now let's try a new model with more neurons in the hidden layer."
      ],
      "id": "coordinated-mexican"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "cathedral-exercise"
      },
      "outputs": [],
      "source": [
        "model2 = Net(D_in, 1000, D_out)"
      ],
      "id": "cathedral-exercise"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "exposed-league"
      },
      "outputs": [],
      "source": [
        "# MSE loss\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "# SGD optimizer for finding the weights of the network\n",
        "optimizer = torch.optim.SGD(model2.parameters(), lr=1e-4)"
      ],
      "id": "exposed-league"
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "operational-paper"
      },
      "outputs": [],
      "source": [
        "losses2 = []\n",
        "\n",
        "for t in range(500):\n",
        "    y_pred = model2(X_train)\n",
        "    \n",
        "    loss = criterion(y_pred, y_train)\n",
        "    # print(t, loss.item())\n",
        "    losses2.append(loss.item())\n",
        "    \n",
        "    if torch.isnan(loss):\n",
        "        break\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "id": "operational-paper"
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "extra-consortium",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "09d82f0d-5e51-40bd-9943-e8e5e4143b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff0d1a9b450>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD8CAYAAABuHP8oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwV5Z3v8c/vLL1CAw1Ni7QKriyCLC1KRKOgRo0z4nJdhlGM5mISdczNzM2QzNwY75htck00k8SXjhvjFhUVHDVxQY1GE5BNFpGICNIIdNPs0Ns557l/VHVzaLrtbvp0H6rr+369+lVVz6lT5ylsv+fpp56nypxziIhI8ESyXQERETk0CnARkYBSgIuIBJQCXEQkoBTgIiIBpQAXEQmoNgPczE4ys6VpP7vM7NtmVmxmr5nZx/6yX3dUWEREPNaRceBmFgU2AqcBNwPbnHM/NbOZQD/n3D93TTVFRKS5jnahTAE+cc6tBy4BZvnls4CpmayYiIh8sVgH978aeNJfL3XObfLXNwOlLb3BzGYAMwAKCwvHDxs27FDqCcCeugSfbt3LcSWFFOTEYN822LEeBo6AWO4hH1dE5HC2aNGirc65kubl7e5CMbMc4HNgpHNui5ntcM71TXt9u3PuC/vBy8vL3cKFCztY9f3e+biKax9cwOxvTKR8SDF88BQ8PwNuXQz9jzvk44qIHM7MbJFzrrx5eUe6UC4EFjvntvjbW8xskH/wQUBl56vZQeZXX/dzEZEQ6kiAX8P+7hOAF4Dp/vp0YG6mKtVuZt7Spbr9o0VEsq1dAW5mhcB5wHNpxT8FzjOzj4Fz/e3upQAXkRBr10VM59xeoH+zsmq8USnZ09iFgrpQRA53DQ0NVFRUUFtbm+2qHLby8vIoKysjHo+3a/+OjkI5vDT1gasFLnK4q6iooHfv3gwZMgRr/OtZmjjnqK6upqKigqFDh7brPcGeSq8AFwmM2tpa+vfvr/BuhZnRv3//Dv2FogAXkW6j8P5iHf33CXaAo4uYIhJewQ5wjQMXkSwZMmQIW7dubfc+N9xwAwMHDuTkk0/OWB0U4CIi3eD666/nD3/4Q0aP2UMCXF0oItK2devWMWzYMK6//npOPPFEpk2bxuuvv84ZZ5zBCSecwIIFC9i2bRtTp05l9OjRnH766SxbtgyA6upqzj//fEaOHMnXv/510m9D8thjjzFhwgTGjBnDTTfdRDKZPOizzzrrLIqLizN6PgEfRugvFeAigXLHf6/kw893ZfSYI44s4va/GdnmfmvWrOGZZ57hoYce4tRTT+WJJ57gT3/6Ey+88AI//vGPOeqooxg7dixz5szhjTfe4LrrrmPp0qXccccdTJo0iR/84Ae89NJLPPjggwCsWrWKp556infffZd4PM63vvUtHn/8ca677rqMnl9LAh7gmsgjIh0zdOhQRo0aBcDIkSOZMmUKZsaoUaNYt24d69ev59lnnwVg8uTJVFdXs2vXLt5++22ee86bjP7Vr36Vfv28e/fNmzePRYsWceqppwJQU1PDwIEDu+VcekaAqwUuEijtaSl3ldzc/beejkQiTduRSIREItHuWZCNnHNMnz6dn/zkJxmtZ3uoD1xEJM2ZZ57J448/DsBbb73FgAEDKCoq4qyzzuKJJ54A4Pe//z3bt28HYMqUKcyePZvKSu+GrNu2bWP9+vXdUlcFuIhImh/+8IcsWrSI0aNHM3PmTGbN8h48dvvtt/P2228zcuRInnvuOY4++mgARowYwZ133sn555/P6NGjOe+889i0adNBx73mmmuYOHEiq1evpqysrKkPvTOC3YWiiTwi0gFDhgxhxYoVTduPPPJIi6/NmTPnoPf279+fV199tcXjXnXVVVx11VUHla9bt65p/cknnzzo9c7qIS1wXcQUkfDpIQGuFriIhE8PCXC1wEUkfAIe4OoDF5HwUoCLiARUwANcMzFFJLx6RoCrBS4i3awjt5PdsGED55xzDiNGjGDkyJHcc889GalDsMeBK8BFJABisRh33XUX48aNY/fu3YwfP57zzjuPESNGdOq4wW6BayKPiHRAtm4nO2jQIMaNGwdA7969GT58OBs3buz0+bSrBW5mfYEHgJPxOpxvAFYDTwFDgHXAlc657Z2uUUdoGKFIMP1+JmxentljHjEKLvxpm7tl+3ay69atY8mSJZx22mmdPuX2dqHcA/zBOXeFmeUABcD3gXnOuZ+a2UxgJvDPna5RR6gLRUQ6KJu3k92zZw+XX345d999N0VFRZ0+lzYD3Mz6AGcB1wM45+qBejO7BDjb320W8BYKcBFpj3a0lLtKtm4n29DQwOWXX860adO47LLLOl7xFrSnD3woUAU8bGZLzOwBMysESp1zjbfc2gyUtvRmM5thZgvNbGFVVVVGKr3/4OpCEZHM6orbyTrnuPHGGxk+fDjf+c53MlbX9gR4DBgH3OucGwvsxesuSa+co5XB2M65+51z5c658pKSks7W90CayCMiGdYVt5N99913efTRR3njjTcYM2YMY8aM4eWXX+50XdvTB14BVDjn5vvbs/ECfIuZDXLObTKzQUBlp2vTUdb0UMxu/2gRCZ5s3U520qRJB4xayZQ2W+DOuc3ABjM7yS+aAnwIvABM98umA3MzXru2qA9cREKsvaNQbgUe90egrAW+hhf+T5vZjcB64MquqeIXUICLSIi1K8Cdc0uB8hZempLZ6nSU+sBFgsQ5hzV1fUpzHe1mCfZMTI1CEQmMvLw8qquru6QvuCdwzlFdXU1eXl6736N7oYhItygrK6OiooKMDyfuQfLy8igrK2v3/gpwEekW8XicoUOHZrsaPUoP6UJRgItI+AQ8wBsvYqpPTUTCJ+ABrifyiEh4BTzANYxQRMIr4AGuPnARCa9gB7gm8ohIiAU7wNUCF5EQ6yEBrouYIhI+PSTA1QIXkfBRgIuIBFTAA1wTeUQkvAIe4JrIIyLh1TMCXF0oIhJCAQ9wvwsllcxuPUREsiDYAQ5gUXAKcBEJn+AHeCSqFriIhFIPCPCYWuAiEkrBD3BTC1xEwin4AR6JKMBFJJTa9UxMM1sH7AaSQMI5V25mxcBTwBBgHXClc25711Tziyqni5giEk4daYGf45wb45wr97dnAvOccycA8/zt7heJQSqRlY8WEcmmznShXALM8tdnAVM7X51DoFEoIhJS7Q1wB7xqZovMbIZfVuqc2+SvbwZKW3qjmc0ws4VmtrCqqqqT1W3pA6KaiSkiodSuPnBgknNuo5kNBF4zs4/SX3TOOTNr8YYkzrn7gfsBysvLM3/TErXARSSk2tUCd85t9JeVwPPABGCLmQ0C8JeVXVXJLxSJqg9cREKpzQA3s0Iz6924DpwPrABeAKb7u00H5nZVJb+4ghqFIiLh1J4ulFLgefNuHBUDnnDO/cHM3geeNrMbgfXAlV1XzS+gLhQRCak2A9w5txY4pYXyamBKV1SqQyIxXcQUkVAK/kxMi6gPXERCKfgBri4UEQmpHhDguhuhiIRT8APcNIxQRMIp+AEeiUJKFzFFJHyCH+AWUReKiIRS8AM8EtNFTBEJpR4Q4OoDF5FwCn6Aayq9iIRU8ANcFzFFJKR6SICrC0VEwif4Aa4uFBEJqeAHuKbSi0hI9YAA11R6EQmnQAW4YQCk0h/MZmqBi0g4BSrAoxEvwJPpCR6JKMBFJJQCFeCxqBfgifRhg7qIKSIhFawAjzQGeHoLXFPpRSScAhbgXnUTyfQA1zhwEQmnYAV4YxdKsnkXimZiikj4BCvAW+xC0SgUEQmnYAV41O9CSb+IqS4UEQmpdge4mUXNbImZvehvDzWz+Wa2xsyeMrOcrqump6kFnt4HrlEoIhJSHWmB3wasStv+GfBL59zxwHbgxkxWrCX7hxGqC0VEpF0BbmZlwFeBB/xtAyYDs/1dZgFTu6KC6ZpGoTQfRojTLWVFJHTa2wK/G/gu0JiS/YEdzrnGzucKYHCG63aQ/V0ozUahgLpRRCR02gxwM7sYqHTOLTqUDzCzGWa20MwWVlVVHcohmuwfRthsKj2oG0VEQqc9LfAzgL81s3XA7/C6Tu4B+ppZzN+nDNjY0pudc/c758qdc+UlJSWdqmyLXShqgYtISLUZ4M657znnypxzQ4CrgTecc9OAN4Er/N2mA3O7rJa+FifyRPzvEA0lFJGQ6cw48H8GvmNma/D6xB/MTJVa1+pEHlAXioiETqztXfZzzr0FvOWvrwUmZL5KrTMzohE7+G6EoOn0IhI6gZqJCV4rXC1wEZGgBnjzuxGC+sBFJHSCF+DRSLMn8sS9pQJcREImeAEeMRrSR6FE/VuwJBuyUyERkSwJXoBHm3WhRP0WeLIuOxUSEcmS4AV4JHLgRcymFnh9diokIpIlwQvwaLNhhOpCEZGQCl6ANx9G2NSFoha4iIRLAAM8cuBUenWhiEhIBS/Ao3bgMMKYulBEJJyCF+ARoyGpi5giIsEL8GiklYuYCnARCZfABXi0+VT6pouY6kIRkXAJXIDHo81HoagFLiLhFLgA10QeERFPAAPcmg0jVBeKiIRT8AK8+TBCtcBFJKSCF+CRSCt3I1SAi0i4BC7Ac2MR6hItPNRYXSgiEjLBC/B49MAAN/Na4WqBi0jIBC/AYxFqG5o9/zKaoxa4iIRO4AI8Lx6lrqHZE+ijcbXARSR02gxwM8szswVm9oGZrTSzO/zyoWY238zWmNlTZpbT9dX1WuD1yRSp5iNREnoij4iES3ta4HXAZOfcKcAY4AIzOx34GfBL59zxwHbgxq6r5n55ce8p9Af0g6sLRURCqM0Ad549/mbc/3HAZGC2Xz4LmNolNWwmN+ZVuS6R1g+uLhQRCaF29YGbWdTMlgKVwGvAJ8AO51zC36UCGNw1VTxQYwu8tqF5C1wBLiLh0q4Ad84lnXNjgDJgAjCsvR9gZjPMbKGZLayqqjrEau7XegtcXSgiEi4dGoXinNsBvAlMBPqamT+LhjJgYyvvud85V+6cKy8pKelUZeGLWuC6iCki4dKeUSglZtbXX88HzgNW4QX5Ff5u04G5XVXJdHlxr8oHjAWPF0BDTXd8vIjIYSPW9i4MAmaZWRQv8J92zr1oZh8CvzOzO4ElwINdWM8mubEWRqHEC2D3pu74eBGRw0abAe6cWwaMbaF8LV5/eLdqsQWeUwgN+7q7KiIiWRW4mZgttsBzCqBeAS4i4RK4AG+5D7wQGvZmqUYiItkRuABvvQWuABeRcAlcgLfaAk8lIKHJPCISHoEL8MYW+IEXMQu8pbpRRCREAhfgBblegO+rbzYOHHQhU0RCJXABHo9GKMiJsqsmbep8TqG31FBCEQmRwAU4QFFenF21LQS4LmSKSIgEM8DzY+yqSewvaOpCUYCLSHgEM8Dz4uyuUxeKiIRbIAO8d16zFnhTF8qelt8gItIDBTLAi/Kb9YHn9/OWNduzUyERkSwIZoDnxQ8chZJf7C33VWenQiIiWRDMAM+Psbs2gXP+k+njeZDTC/Zty27FRES6UTADPC9OIuUOnMxT0B/2bs1epUREulkgA7ykdy4AlbvTHqNW0F9dKCISKoEM8CP65AGwaWfaY9QKByjARSRUAhngR/bJB2DTjtr9hWqBi0jIBDLAG1vgm3elBXhhCeyphFSqlXeJiPQsgQzwvHiUfgVxPt+R1oVSPBSSdbBrY/YqJiLSjQIZ4ABHFRewvjpt6nzxcd5y29rsVEhEpJsFNsCHH1HEh5t27R8LXnyst9z2SfYqJSLSjQIb4CMHF7Ftb/3+fvCiwRDLh6q/ZrdiIiLdpM0AN7OjzOxNM/vQzFaa2W1+ebGZvWZmH/vLfl1f3f1GHtkHgMXrd3gFkQiUlcNn73VnNUREsqY9LfAE8I/OuRHA6cDNZjYCmAnMc86dAMzzt7vNKWV96FsQZ96qLfsLh0yCTcs0pV5EQqHNAHfObXLOLfbXdwOrgMHAJcAsf7dZwNSuqmRLYtEIk4cN5LVVW9hb599a9sQLAAfLnu7OqoiIZEWH+sDNbAgwFpgPlDrnNvkvbQZKW3nPDDNbaGYLq6qqOlHVg/396cewuzbBo39Z7xUcOQbKJsC7d+vWsiLS47U7wM2sF/As8G3n3K7015w3FMS19D7n3P3OuXLnXHlJSUmnKtvcuKP7MWXYQO5+/a+s2+o/Tu2if/duavXopRpSKCI9WrsC3MzieOH9uHPuOb94i5kN8l8fBFR2TRW/2I8uHUU8EuG23y1hX30CjhwLVz0K1Wvht1+CP3wPdlZko2oiIl2qPaNQDHgQWOWc+0XaSy8A0/316cDczFevbUf0yeOuK09h+cad3PrEEhLJFJx0Idz8Fxg5FRbcD/ecAs9+Hda/B67FPxRERALHXBuBZmaTgHeA5UDjjUa+j9cP/jRwNLAeuNI594XDP8rLy93ChQs7W+cWPfaX9fzrnBVcOnYwP79iNLGo/920YwP8+Tew9HGo2wUlw6D8Bhh9FeT37ZK6iIhkkpktcs6VH1TeVoBnUlcGOMBv3lzDz19ZzVdHD+Luq8YQj6b9gVG/F1Y8Bwsfgs8Xe5N+Tr4cyr8Gg8eDWZfVS0SkM1oL8Fg2KtNVbj7neHKiEX708irqEyl+/XdjyY1FvRdzCmHctd7P50tg4cOwfDYsfQxKT4Zx02H0lWqVi0hg9KgWeKP/+vM6fjB3JZOOH8C9fz+O3nnxlnes3QUrZsOiR2DTB16rfOSlMP56OGqCWuUiclgIRRdKutmLKpj57DKOH9iLR742oeke4q36fAksmgXLn4H6PVAy3Avy0VdCQXG31FlEpCWhC3CAt/9axTcfW0Sf/DiP3DCBE0t7t/2muj2w4lmvVf75YojmeqNZxl8PR09Uq1xEul0oAxxg5ec7+drD71PTkOS+a8fzpeMGtP/Nm5bB4lne1Py6XTDgRC/IT7lGrXIR6TahDXCAjTtquP6hBXy6dS93XDKSaacd07ED1O+Flc97XSwVC7xW+SlXw8RboOTErqm0iIgv1AEOsLOmgdt+t4S3Vlcx7bSjuf1vRpITO4TboW9ZCQv+Ez54EhK1cOKFcMY/qHtFRLpM6AMcIJly/PsrH3HfH9cyYWgxv502jgG9cg/tYHuq4P0HvJmeNdtgcDmcPROOP1dBLiIZpQBPM3fpRr47exkDeuVy37XjOXlwn0M/WP0+b5bnu7+CnZ95QX7O9+G4yQpyEcmI1gI8sI9U64xLxgxm9je+RMo5Lr/3PZ5+f8OhHyynACb8T7h1EVx8N+zeDI9dBg9dABsWZK7SIiLNhDLAAUaV9eG/b53E+GP68d1nl/Hd2R9Q25A89APGcrxp+f+wGL56F+xYDw+eB8/NgF2fZ67iIiK+0AY4wIBeuTx642nccs7xPL2wgst++x7rq/d27qCxXDj163DLQjjzn2DlHPiP8fDOXZBsyEzFRUQIeYADRCPGP33lJB66vpyNO2q4+D/+xCsrN3f+wLm9YMr/gZvne/3h8/4v3H+2N+NTRCQDQh/gjSYPK+XFWycxdEAhNz26iJ+8vMq7t3hnFQ+Fqx+Hq5/0nhT0n5PhtR9AQ03njy0ioaYAT3NUcQHPfGMi0047mvveXsvfPTCfyl21mTn4sIu81viYafDuPXDfl72ZniIih0gB3kxuLMqPLh3FL686heUVO7noV3/ivTVbM3Pw/L5wya/h75+D2p3wwBR479eQykBLX0RCRwHeikvHljHn5jPokx9j2oPz+cWrqzPTpQJw/BT45ntw/Hnw6r94ww53Z6DfXURCRQH+BU46ojcv3DKJy8aW8as31vB3D8xn884MdakU9vf6xi++Gz77C/x2Inz0cmaOLSKhoABvQ2FujLuuPIVfXHkKKzbu5MJ73uaNj7Zk5uBm3tjxm96GPmXwu2vgxf/lze4UEWmDArydLhtXxn/fOonSojxueGQhP3rpQ+oTGepSKTkRvv46fOlW75md952l4YYi0iYFeAccV9KLOTefwbWnH8N/vvMp/+O+P7NhW4Zay7FcOP9OuG6ud/vaB86Ft/8fpDoxO1REejQFeAflxaP829STuXfaONZW7eGiX73Dy8s3Ze4Djj0bvvkuDP8beOPf4OGLYPu6zB1fRHqMNgPczB4ys0ozW5FWVmxmr5nZx/6yX9dW8/Bz4ahBvPwPZ3JsSS++9fhi/nXO8s7dSyVdQTFc8TBcej9Ufgj3ToKlT0I33jlSRA5/7WmBPwJc0KxsJjDPOXcCMM/fDp2jigt45qaJzDjrWB77y2dc8ut3WbVpV2YObganXAXf+BMcMQrmfAOeme7dh1xEhHYEuHPubWBbs+JLgFn++ixgaobrFRg5sQjfv2g4D3/tVKr31nPJr9/lgXfWkkplqLXc7xi4/kWYcjus/j385lRY+oRa4yJyyH3gpc65xo7fzUBpazua2QwzW2hmC6uqem7r8ZyTBvLKt8/kyyeVcOdLq7j2ofls2pmh+51EonDmd7zW+ICTYM434dGpsG1tZo4vIoHU6YuYznukT6vNQefc/c65cudceUlJSWc/7rDWv1cu9187np9eNorF63dwwd3v8OKyDN4LvOQk+NrvvfuNVyyC334J3vqZxo2LhNShBvgWMxsE4C8rM1elYDMzrp5wNC/fdiZDBhRyyxNL+OZji6jcnaEZnJGId7/xm+fDiefDWz+GX58Ky2erW0UkZA41wF8Apvvr04G5malOzzF0QCGzvzGR//2Vk5j3USXn3vVHnn5/Axl7BmmfwXDlf8H1L0FBP3j2RnjwfPj07cwcX0QOe20+1NjMngTOBgYAW4DbgTnA08DRwHrgSudc8wudBzlcHmrc3dZW7WHmc8tZ8Ok2zji+P3dOHcXQAYWZ+4BUEpY8Bm/9BHZvgiFnwuR/haNPz9xniEjW6Kn0WZZKOZ58/zN++vJH1CaS3HDGUG6ZfDy98+KZ+5CGWlj0MLzzC9hbCUPPgom3wvHnel0vIhJICvDDRNXuOn7+ykc8s6iC/oW5fPcrJ3H5+DKiEcvch9TvhfcfhL/cC7s/90auTLwZRl8F8bzMfY6IdAsF+GFmWcUOfvjCShZ/toNjSwr59rkncvGoQUQyGeSJelj5PPz5P2DzcsgvhlOuhrHXQumIzH2OiHQpBfhhyDnHKys388vXPmb1lt2cWNqLWyefwIUnH0EsmsEuD+e8i5sLH/TuOZ5qgMHjvSAfcYk3dV9EDlsK8MNYKuV4afkm7n79r3xStZcj++Rx3ZeGcPWpR9G3ICezH7Z3Kyx7ChY/ClWrwKJeX/nIqTDsYigckNnPE5FOU4AHQDLlePOjSh5691Pe+6SanFiE84aXcvn4wZx1QknmW+WbPoAP58KHc7xZnRaBslPhuClw3GQYPM6bBSoiWaUAD5hVm3bx1PsbmLt0I9v3NTCgVy4XnFzKucNLmXhcf3JjGQxW52DLSlj1Aqx5HTYuBhzk9YUhk+CoCVA2AY4cA/H8zH2uiLSLAjyg6hMp3lxdyfOLN/LHv1ZR05CkMCfKmSeUMPG4/px2bDEnDuyd2Yuf+7bB2jfhkzdg/Z9h2ydeeSQOg0bDkWOhdCSUngwDh0Nu78x9togcRAHeA9Q2JPnzJ9W8vmoLb62uYuMO72ZZfQvijDu6HycfWcSII/tw8uAiBvfNxyxDob53K2xYABULvOXm5VCXdtvcvsfAwBFQfCwUD4V+Q71ln6MgluE+fJEQUoD3QBu27WP+p9uYv7aaDyp2sKZyD413sS3KizG0pBfHDihkqP9zTP8CjuiTx4DC3M612J2DnRu8bpctK2DLh1C5yntyUCLtDowWgaIyKDoSeh8BvQcduOw10BvaWFAM0QxOaBLpYRTgIVBTn+SjzbtY+fkuPtq8i3Vb9/Hp1r1NLfVGsYhRWpTHEX3yOKIoj4FFuRQX5NCvMIfiwhz6FeTQrzBOcUEOfQtyyIm18+Kpc7B7M2z/FLZ96i23r/em9+/e7P3U7275vTm9vXu6NAZ6fjHk9/W6Z3J7e6/n9obcXs22/bJ4oWabSo+lAA+xmvok67ft5bPqfWzZVcumnbVs3uktt+zyfvbWt/44uNxYhN55MXrlxijM9ZYHbOfF6J0bIz8nRn48Sn5OhLxYlLycKPnxKHnxxmWEAldDfn0VufuqiNVUYjXbvT73mm0HL2t2QP0eSCXad6KxPO8nXuDNOI0X+Nv5+39i+Qdvx3Igmusvm6/neA+cjuZ6fyXEcpuVp61rxI50kdYCPJaNykj3ys+JMuyIIoYdUdTqPnWJJDv2NbBtbz3b99WzfW+Dv6xnT12C3XUJ9tYl2FPrrW/aWcsef3tPXYK6RKrD9YpGCsiP9yYvPoTcWJTcWIScxp+cCDkFEXKiRn4kSVGkhiKrpbfVUGi1FLp9FFLjfSG4feS5GnJdPTmujrirI56qI56qJZasI9ZQQzS5g2iyhkiyjkiihkiiFkvUYC5DzzEFb0x9NCftCyEXIjEv+CNxiMb8ZbxZefPt9uwX68Ax0rYb3xeJpK3HvLpHomll/nqmrqNIl1CACwC5sSilRVFKiw7tXin1iRQ1DUlqG5LU1CepTfjLhpRX1via/3pdIkVN/f7y2oYU9ckU9Ykk9YnG9RR761JsTqSoT0apT+RTn8hteq0+kSLRyUfXxUiQQ4IcGryleev5kQT5kST50SQFkSR5liAvkiQ/kiDPkuRagrxIglxLkOtv59JA3JLk+seK00A8lSTmEsRckhgJYiSJ0kDU1RB1Ce+HJBGXIOISRFOJpvVIKoH5y4hr6NR5HjKLpAV8WrA3X1rz8E/btmZfFge93tqXR8Rbb3zdot4Xj0WalUVb2beN8laP33zfdpQfdKxIt3z5KcAlIxpbzn3yu/diZCrlqE+mqPMDPT3cvW3vy6Ih6Ugk/WUqRUPjetL5696XQSKZot7fN5Fy/pdEyt/PsS2Z8t/vva/x/YmUSztm2vH999b7+za+t+McUVLESBL3vwjiJImRJGYJ4iSJkmp6rel1/7XGsigpov56TiRFzBw5liIeSZFj3nbcUsQtRcz/iVuSGI6YJYmRIupSxJJJosmUt914XEsRc0miliTqUkRIEKXOfz1JhBRRl75MEnHee7NxAS4AAAVsSURBVC1tu+nHLzeXIkLH/8LLuuZfNDf9EQackNGPUIBLoEUiRl7E62cPCuccKQeJVIpkypFIOZJJf5lyB5SnUunljqT/hZBsqbxxO9lyeavvSTrqUo59LR0rrW4p55U1LhvXU44Wy70lLZY1raccSXfw6y38qxHxv8Qi/k80bRnF7V+3ll4/eD2CO2DfaIvHTTU7rmvlWPvr0PjFFzXnfcFZihiOL++NMyTDd6pQgIt0MzMjahDVRc8WuRa+FFLOkUpxUNg33yeZIu2LpeXypP+lkUod+PqB7/H+umv6gnIOl/aaa/ZllErt3y/lHDUt7Ner/6CM/1spwEXksLL/C04XUNuigbMiIgGlABcRCSgFuIhIQCnARUQCSgEuIhJQnQpwM7vAzFab2Rozm5mpSomISNsOOcDNLAr8BrgQGAFcY2Z61LmISDfpTAt8ArDGObfWOVcP/A64JDPVEhGRtnRmIs9gYEPadgVwWvOdzGwGMMPf3GNmqw/x8wYAWw/xvUGlcw4HnXM4dOacj2mpsMtnYjrn7gfu7+xxzGxhS/fD7cl0zuGgcw6HrjjnznShbASOStsu88tERKQbdCbA3wdOMLOhZpYDXA28kJlqiYhIWw65C8U5lzCzW4BXgCjwkHNuZcZqdrBOd8MEkM45HHTO4ZDxc+7WZ2KKiEjmaCamiEhAKcBFRAIqEAHeU6fsm9lDZlZpZivSyorN7DUz+9hf9vPLzcx+5f8bLDOzcdmr+aExs6PM7E0z+9DMVprZbX55Tz7nPDNbYGYf+Od8h18+1Mzm++f2lD8QADPL9bfX+K8PyWb9O8PMoma2xMxe9Ld79Dmb2TozW25mS81soV/Wpb/bh32A9/Ap+48AFzQrmwnMc86dAMzzt8E7/xP8nxnAvd1Ux0xKAP/onBsBnA7c7P+37MnnXAdMds6dAowBLjCz04GfAb90zh0PbAdu9Pe/Edjul//S3y+obgNWpW2H4ZzPcc6NSRvv3bW/285/1tvh+gNMBF5J2/4e8L1s1yuD5zcEWJG2vRoY5K8PAlb76/cB17S0X1B/gLnAeWE5Z6AAWIw3Y3krEPPLm37H8UZ1TfTXY/5+lu26H8K5lvmBNRl4EbAQnPM6YECzsi793T7sW+C0PGV/cJbq0h1KnXOb/PXNQKm/3qP+Hfw/k8cC8+nh5+x3JSwFKoHXgE+AHc65hL9L+nk1nbP/+k6gf/fWOCPuBr4LpPzt/vT8c3bAq2a2yL+FCHTx77YeanwYc845M+tx4zzNrBfwLPBt59wus/0Pr+2J5+ycSwJjzKwv8DwwLMtV6lJmdjFQ6ZxbZGZnZ7s+3WiSc26jmQ0EXjOzj9Jf7Irf7SC0wMM2ZX+LmQ0C8JeVfnmP+HcwszheeD/unHvOL+7R59zIObcDeBOv+6CvmTU2oNLPq+mc/df7ANXdXNXOOgP4WzNbh3eX0snAPfTsc8Y5t9FfVuJ9UU+gi3+3gxDgYZuy/wIw3V+fjtdP3Fh+nX/1+nRgZ9qfZoFgXlP7QWCVc+4XaS/15HMu8VvemFk+Xp//Krwgv8Lfrfk5N/5bXAG84fxO0qBwzn3POVfmnBuC9//rG865afTgczazQjPr3bgOnA+soKt/t7Pd8d/OiwMXAX/F6zv8l2zXJ4Pn9SSwCWjA6wO7Ea/vbx7wMfA6UOzva3ijcT4BlgPl2a7/IZzvJLx+wmXAUv/noh5+zqOBJf45rwB+4JcfCywA1gDPALl+eZ6/vcZ//dhsn0Mnz/9s4MWefs7+uX3g/6xszKmu/t3WVHoRkYAKQheKiIi0QAEuIhJQCnARkYBSgIuIBJQCXEQkoBTgIiIBpQAXEQmo/w9VxAT9YaWcNwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(losses1, label=\"model1\")\n",
        "plt.plot(losses2, label=\"model2\")\n",
        "plt.ylim([0, 70])\n",
        "plt.legend()"
      ],
      "id": "extra-consortium"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "banned-honolulu"
      },
      "source": [
        "Let's compare the MSE loss on the test data"
      ],
      "id": "banned-honolulu"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "parallel-following",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c303ed3-9eeb-4cde-a246-3c58d7547290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE loss for model1:  tensor(0.3020, grad_fn=<MseLossBackward0>)\n",
            "MSE loss for model2:  tensor(0.3095, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# prediction for model 1\n",
        "model1_pred = model1(x_test)\n",
        "print(\"MSE loss for model1: \", criterion(model1_pred, y_test))\n",
        "# prediction for model 2\n",
        "model2_pred = model2(x_test)\n",
        "print(\"MSE loss for model2: \", criterion(model2_pred, y_test))\n"
      ],
      "id": "parallel-following"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrong-corporation"
      },
      "source": [
        "## Now it is your turn!\n",
        "### Exercises\n",
        "\n",
        "1- Let's get back to model1. This time try to train it with a new optimizer. Try the Adam optimizer (which has shown to be faster than SGD for non-convex functions) and compare the trainig loss curve with SGD. Plot the training loss for the model trained with SGD and Adam optimizer.\n",
        "\n",
        "Note1: Use `torch.optim.Adam(model1.parameters(), lr=...)`\n",
        "\n",
        "Note2: If you are interested, check [this nice post](https://ruder.io/optimizing-gradient-descent/index.html) on differen gradient descent optimization algorithms.\n",
        "\n",
        "2- This time we want to build a new model with a new architecture. Specifically, we want to train a network with 3 hidden layers on the data. You can use the following code to build the architecture. Use the values 500, 1000, 200 for H1, H2, and H3 respectively. Train this new network on the same training data and compare it with the model1 we built above.\n",
        "\n",
        "```\n",
        "class Net_new(nn.Module):\n",
        "    def __init__(self, D_in, H1, H2, H3, D_out):\n",
        "        super(Net_new, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(D_in, H1)\n",
        "        self.linear2 = nn.Linear(H1, H2)\n",
        "        self.linear3 = nn.Linear(H2, H3)\n",
        "        self.linear4 = nn.Linear(H3, D_out)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = self.activation(self.linear1(x))\n",
        "        y_pred = self.activation(self.linear2(y_pred))\n",
        "        y_pred = self.activation(self.linear3(y_pred))\n",
        "        y_pred = self.linear4(y_pred)\n",
        "        return y_pred\n",
        "```"
      ],
      "id": "wrong-corporation"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "respiratory-drink"
      },
      "outputs": [],
      "source": [],
      "id": "respiratory-drink"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}