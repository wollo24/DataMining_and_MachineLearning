{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/michalis0/DataMining_and_MachineLearning/blob/master/week9/Text_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onO46LysT2dh"
   },
   "source": [
    "# Data Mining and Machine Learning - Week 9\n",
    "# Text Analytics\n",
    "\n",
    "[Text Analytics](https://people.ischool.berkeley.edu/~hearst/text-mining.html) (or text mining) is the process of deriving high-quality information from text. It involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\" Written resources may include websites, books, emails, reviews, and articles.\n",
    "\n",
    "### Table of Contents\n",
    "#### 1. Summary\n",
    "* 1.1 Applications\n",
    "* 1.2 Tokenization and Stopwords\n",
    "* 1.3 Stemming and Lemmatization\n",
    "* 1.4 Text Representation\n",
    "\n",
    "#### 2. Text Preparation\n",
    "* 2.1 Install spaCy\n",
    "* 2.2 Tokenization\n",
    "* 2.3 Dependency Parsing\n",
    "* 2.4 Remove Stopwords\n",
    "* 2.5 Lemmatization\n",
    "* 2.6 Entity Detection\n",
    "* 2.7 Exercise\n",
    "* 2.8 Solution\n",
    "\n",
    "#### 3. Text Representation\n",
    "* 3.1 Bag of Words (BOW)\n",
    "* 3.2 TF-IDF Representation\n",
    "* 3.3 Exercise\n",
    "* 3.4 Solution\n",
    "\n",
    "#### 4. Text Classification: Alexa Reviews\n",
    "* 4.1 Load and prepare data\n",
    "* 4.2 Classification of the reviews using logistic regression\n",
    "* 4.3 How can we improve the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0VsVUPLT4Tn"
   },
   "source": [
    "## 1. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHvrJj5yT8uQ"
   },
   "source": [
    "### 1.1 Applications\n",
    "There are many applications of text analytics, for example:\n",
    "* Search for relevant websites or articles using a search engine\n",
    "* Sentiment Analysis (e.g. classify tweets or film reviews as positive, neutral or negative)\n",
    "* Chatbots (e.g. Siri, Alexa)\n",
    "* Project idea: The Impact of Donald Trump’s Tweets on Financial Markets\n",
    "* Etc.\n",
    "\n",
    "### 1.2 Tokenization and Stopwords\n",
    "**Tokens** are the elementary building blocks (words, numbers, characters) in a document. Tokenization is the process of splitting an input\n",
    "sequence into tokens. Example: \"I love data science\" --> \"I\", \"love\", \"data\", \"science\". **Stopwords** are common words that appear very frequently (e.g. \"is\", \"and\", \"you\", etc.). It is convenient to remove them as they do not add much to the content of a document and are therefore generally not useful for text analysis or, worse still, make it worse by adding noise.\n",
    "\n",
    "### 1.3 Lemmatization and Stemming\n",
    "* Goal: have the same token for different forms of a word (e.g. fishing, fished, fisher, fishers, etc.)\n",
    "* **Lemmatization**: Find what is the lemma of a word (e.g. feet -> foot)\n",
    "* **Stemming**: one method for lemmatization where rules that remove the ending of a word are applied (e.g. fishing -> fish)\n",
    "\n",
    "\n",
    "### 1.4 Text Representation\n",
    "* Goal: transform text into numerical features such that it can be used ML algorithms.\n",
    "* **Bag of Words (BOW)**: works in many case but order is not preserved (solution: n-grams)\n",
    "* **TF-IDF**: emphasizes important words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXlVy05IUC-D"
   },
   "source": [
    "## 2. Text Preparation\n",
    "In this section, we explain how to prepare a text for analysis. This includes tockeninzing the text, removing stopwords, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA4tt9roTp8T"
   },
   "source": [
    "### 2.1 Install spaCy\n",
    "[spaCy](https://spacy.io/) is an open-source natural language processing library for Python. It is designed particularly for production use, and it can help us to build applications that process massive volumes of text efficiently.\n",
    "\n",
    "We install the library and its English-language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gf6I0JIYTp8U",
    "outputId": "0a907ec7-9ccc-4e1c-e8c2-07ead0abcfff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.10.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "2022-11-08 19:36:21.984456: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting en-core-web-sm==3.4.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.1/en_core_web_sm-3.4.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 2.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.11.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.10)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.10.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (57.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.10.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.4.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.64.1)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (8.1.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.23.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.0.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2022.9.24)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.1) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install and update spaCy\n",
    "!pip install -U spacy\n",
    "\n",
    "# Download the english language model\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FhOeeRlqTp8Z"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUibE-SyTp8d"
   },
   "source": [
    "### 2.2 Tokenization\n",
    "\n",
    "**Tokenization** is the process of breaking a text into pieces called tokens. A token simply refers to an individual part of a sentence having some semantic value. SpaCy‘s tokenizer takes input in form of unicode text and outputs a sequence of token objects. In addition, SpaCy automatically breaks your document into tokens when a document is created using the language model.\n",
    "\n",
    "Let’s take a look at a simple example. Imagine we have the following text, and we would like to tokenize it:\n",
    "\n",
    "> When learning data science, you shouldn't get discouraged!\n",
    "\n",
    "> Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\n",
    "\n",
    "There are a couple of different ways we can appoach this. The first is called __word tokenization__, which means breaking up the text into individual words. This is a critical step for many language processing applications, as they often require inputs in the form of individual words rather than longer strings of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dj9OfB1BTp8e",
    "outputId": "f2c13015-b33d-416f-bcf9-0299e572c720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "When learning data science, you shouldn't get discouraged!\n",
       "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load English language model\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Declare text\n",
    "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
    "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
    "\n",
    "# spaCy object is used to create a document\n",
    "my_doc = sp(text)\n",
    "\n",
    "my_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc7fwTbPZdXJ",
    "outputId": "7ef4ce1e-7219-47f4-8f27-9b03fffaf77b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a spaCy document\n",
    "type(my_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ex7-T-BkYXZM",
    "outputId": "300dae65-c000-4b90-fdb2-b21dd474742a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " 'learning',\n",
       " 'data',\n",
       " 'science',\n",
       " ',',\n",
       " 'you',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'get',\n",
       " 'discouraged',\n",
       " '!',\n",
       " '\\n',\n",
       " 'Challenges',\n",
       " 'and',\n",
       " 'setbacks',\n",
       " 'are',\n",
       " \"n't\",\n",
       " 'failures',\n",
       " ',',\n",
       " 'they',\n",
       " \"'re\",\n",
       " 'just',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'journey',\n",
       " '.',\n",
       " 'You',\n",
       " \"'ve\",\n",
       " 'got',\n",
       " 'this',\n",
       " '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of tokens\n",
    "token_list = []\n",
    "\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "\n",
    "token_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xi29AcSsTp8j"
   },
   "source": [
    "As we can see, spaCy produces a list that contains each token as a separate item. Notice that it has recognized that contractions such as _shouldn’t_ actually represent two distinct words, and has thus broken them down into two distinct tokens.\n",
    "\n",
    "In the example above, we first load the language dictionary. Here we load the english one using `spacy.load('en_core_web_sm')` create an object of this class, \"sp\", which is used to create documents with linguistic annotations and various language properties. After creating the document, we create a list of tokens.\n",
    "\n",
    "We can also see the parts-of-speech (POS) of each of these tokens using the `.pos_` attribute, as shown below. POS tagging can be really useful, particularly if you have words or tokens that can have multiple POS tags. For instance, the word \"fish\" can be used as both a noun and verb, depending upon the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvkGwDJoWoIs",
    "outputId": "9459553d-e026-43b8-ba5b-3fe104a62687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When SCONJ\n",
      "learning VERB\n",
      "data NOUN\n",
      "science NOUN\n",
      ", PUNCT\n",
      "you PRON\n",
      "should AUX\n",
      "n't PART\n",
      "get AUX\n",
      "discouraged VERB\n",
      "! PUNCT\n",
      "\n",
      " SPACE\n",
      "Challenges NOUN\n",
      "and CCONJ\n",
      "setbacks NOUN\n",
      "are AUX\n",
      "n't PART\n",
      "failures NOUN\n",
      ", PUNCT\n",
      "they PRON\n",
      "'re AUX\n",
      "just ADV\n",
      "part NOUN\n",
      "of ADP\n",
      "the DET\n",
      "journey NOUN\n",
      ". PUNCT\n",
      "You PRON\n",
      "'ve AUX\n",
      "got VERB\n",
      "this PRON\n",
      "! PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS\n",
    "for word in my_doc:\n",
    "    print(word.text, word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cUsKHgp7Y3yM",
    "outputId": "ef4d07ce-c42c-4094-934a-66513f630bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON\n",
      "like VERB\n",
      "to PART\n",
      "fish VERB\n",
      "-----------------\n",
      "I PRON\n",
      "eat VERB\n",
      "a DET\n",
      "fish NOUN\n"
     ]
    }
   ],
   "source": [
    "# Another example\n",
    "doc1 = sp(\"I like to fish\") # verb\n",
    "doc2 = sp(\"I eat a fish\") # noun\n",
    "\n",
    "for word in doc1:\n",
    "  print(word.text, word.pos_)\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "for word in doc2:\n",
    "  print(word.text, word.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCiU1-PDXKpp"
   },
   "source": [
    "\n",
    "If we want, we can also break the text into sentences rather than words. This is called __sentence tokenization__. When performing sentence tokenization, the tokenizer looks for specific characters that normally fall between sentences, like periods, exclamation points, and newline characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "odi_WkNZTp8k",
    "outputId": "740de7d3-9f7b-47c1-da0f-94e15648ef07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When learning data science, you shouldn't get discouraged!\\n\",\n",
       " \"Challenges and setbacks aren't failures, they're just part of the journey.\",\n",
       " \"You've got this!\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of sentence tokens\n",
    "sents_list = []\n",
    "\n",
    "for sent in my_doc.sents:\n",
    "    sents_list.append(sent.text)\n",
    "\n",
    "sents_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te403rkXbGKf"
   },
   "source": [
    "### 2.3 Dependency Parsing\n",
    "__Depenency parsing__ is a language processing technique that allows to better determine the meaning of a sentence by analyzing how it is constructed to determine how the individual words relate to each other.\n",
    "\n",
    "Consider, for example, the sentence “Joe throws the ball.” We have two nouns (Joe and ball) and one verb (throws). But we can’t just look at these words individually, or we may end up thinking that the ball throws Joe! To understand the sentence correctly, we need to look at the word order and sentence structure, not just the words.\n",
    "\n",
    "Below, we have a short sentence. We’ll use a spaCy method called `noun_chunks`, which breaks the input down into nouns and the words describing them, and iterate through each chunk in our source text, identifying the word, its root, its dependency identification, and which chunk it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFLButK_bOor",
    "outputId": "b49f7fdc-8790-48fa-ed07-ff780dc20992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Joe Joe nsubj threw\n",
      "a ball ball dobj threw\n",
      "President Donald Donald nsubj hit\n",
      "pursuit pursuit pobj in\n",
      "the ball ball pobj of\n",
      "a wall wall dobj hit\n"
     ]
    }
   ],
   "source": [
    "doc = sp(\" Joe threw a ball, and President Donald, in pursuit of the ball, hit a wall.\") # notice the space at the beginning\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "7VmqTQQ9bYTl",
    "outputId": "0aa614eb-1543-49ec-dbb1-5761a7455ec1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"975d014133e84a8bb8943461abf563e9-0\" class=\"displacy\" width=\"1970\" height=\"377.0\" direction=\"ltr\" style=\"max-width: none; height: 377.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"> </tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">Joe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">threw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">ball,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">President</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">Donald,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">pursuit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">ball,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1610\">hit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1610\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"287.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">wall.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-0\" stroke-width=\"2px\" d=\"M70,242.0 C70,182.0 155.0,182.0 155.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,244.0 L62,232.0 78,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-1\" stroke-width=\"2px\" d=\"M190,242.0 C190,182.0 275.0,182.0 275.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M190,244.0 L182,232.0 198,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-2\" stroke-width=\"2px\" d=\"M430,242.0 C430,182.0 515.0,182.0 515.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,244.0 L422,232.0 438,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-3\" stroke-width=\"2px\" d=\"M310,242.0 C310,122.0 520.0,122.0 520.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520.0,244.0 L528.0,232.0 512.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-4\" stroke-width=\"2px\" d=\"M310,242.0 C310,62.0 645.0,62.0 645.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M645.0,244.0 L653.0,232.0 637.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-5\" stroke-width=\"2px\" d=\"M790,242.0 C790,182.0 875.0,182.0 875.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,244.0 L782,232.0 798,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-6\" stroke-width=\"2px\" d=\"M910,242.0 C910,62.0 1605.0,62.0 1605.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,244.0 L902,232.0 918,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-7\" stroke-width=\"2px\" d=\"M910,242.0 C910,182.0 995.0,182.0 995.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M995.0,244.0 L1003.0,232.0 987.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-8\" stroke-width=\"2px\" d=\"M1030,242.0 C1030,182.0 1115.0,182.0 1115.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,244.0 L1123.0,232.0 1107.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-9\" stroke-width=\"2px\" d=\"M1150,242.0 C1150,182.0 1235.0,182.0 1235.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1235.0,244.0 L1243.0,232.0 1227.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-10\" stroke-width=\"2px\" d=\"M1390,242.0 C1390,182.0 1475.0,182.0 1475.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1390,244.0 L1382,232.0 1398,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-11\" stroke-width=\"2px\" d=\"M1270,242.0 C1270,122.0 1480.0,122.0 1480.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1480.0,244.0 L1488.0,232.0 1472.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-12\" stroke-width=\"2px\" d=\"M310,242.0 C310,2.0 1610.0,2.0 1610.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,244.0 L1618.0,232.0 1602.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-13\" stroke-width=\"2px\" d=\"M1750,242.0 C1750,182.0 1835.0,182.0 1835.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1750,244.0 L1742,232.0 1758,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-975d014133e84a8bb8943461abf563e9-0-14\" stroke-width=\"2px\" d=\"M1630,242.0 C1630,122.0 1840.0,122.0 1840.0,242.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-975d014133e84a8bb8943461abf563e9-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1840.0,244.0 L1848.0,232.0 1832.0,232.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize this\n",
    "displacy.render(doc, style=\"dep\", jupyter= True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_Z6MiCtTp8n"
   },
   "source": [
    "### 2.4 Remove Stopwords\n",
    "Most text data that we work with is going to contain a lot of words that are not actually useful to us. These words, called stopwords, are useful in human speech, but they do not have much to contribute to the meaning of a sentence. Removing stopwords helps us eliminate noise and distraction from our text data, and also speeds up the time of the analysis (since there are fewer words to process). This makes text analysis more efficient.\n",
    "\n",
    "Let’s take a look at the stopwords spaCy includes by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kB8kI0eTp8o",
    "outputId": "0d980a3e-3b63-471b-f761-3ef205f7d2f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 326\n",
      "20 stopwords: ['eight', 'to', 'somewhere', 'rather', 'before', 'became', 'ours', 'also', 'by', 'where', 'across', 'nowhere', 'yourselves', 'a', 'been', 'she', 'becomes', 'therefore', 'whenever', 'mostly']\n"
     ]
    }
   ],
   "source": [
    "# Import stopwords from English language\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Print total number of stopwords\n",
    "print('Number of stopwords: %d' % len(spacy_stopwords))\n",
    "\n",
    "# Print 20 stopwords\n",
    "print('20 stopwords: %s' % list(spacy_stopwords)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aw0Wfvu4Tp8q"
   },
   "source": [
    "Now that we’ve got our list of stopwords, let’s use it to remove the stopwords from the text string we were working on in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq5yvoZtlhsd",
    "outputId": "8566b4f1-3c53-4650-a193-3c9a89ffe276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "When learning data science, you shouldn't get discouraged!\n",
       "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words will be removed?\n",
    "my_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y54Kiz9zTp8r",
    "outputId": "45d56d1f-76e5-4270-9757-f142ce8b5656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning',\n",
       " 'data',\n",
       " 'science',\n",
       " ',',\n",
       " 'discouraged',\n",
       " '!',\n",
       " '\\n',\n",
       " 'Challenges',\n",
       " 'setbacks',\n",
       " 'failures',\n",
       " ',',\n",
       " 'journey',\n",
       " '.',\n",
       " 'got',\n",
       " '!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare list for filtered sentence\n",
    "filtered_sent = []\n",
    "\n",
    "# Filter stopwords\n",
    "for word in my_doc:\n",
    "    if word.is_stop == False:\n",
    "        filtered_sent.append(word.text)\n",
    "\n",
    "filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOvM2NFdl29W",
    "outputId": "9f7b84e2-4cbe-4a08-87f6-f764119ae81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When',\n",
       " ',',\n",
       " 'you',\n",
       " 'should',\n",
       " \"n't\",\n",
       " 'get',\n",
       " '!',\n",
       " '\\n',\n",
       " 'and',\n",
       " 'are',\n",
       " \"n't\",\n",
       " ',',\n",
       " 'they',\n",
       " \"'re\",\n",
       " 'just',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " '.',\n",
       " 'You',\n",
       " \"'ve\",\n",
       " 'this',\n",
       " '!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also remove the punctuation\n",
    "\n",
    "## create empty list to sort the words\n",
    "filtered_sent2 = []\n",
    "removed_tokens = []\n",
    "\n",
    "# Filter stopwords, punctuation and spaces\n",
    "for word in my_doc:\n",
    "  if (word.is_stop == True) or (word.is_punct == True) or (word.is_space == True):\n",
    "    removed_tokens.append(word.text)\n",
    "  else:\n",
    "    filtered_sent2.append(word.text)\n",
    "\n",
    "removed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mw-ebvZom1EP",
    "outputId": "dd85eb51-670e-49bb-c1fa-3f4bd6442d63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learning',\n",
       " 'data',\n",
       " 'science',\n",
       " 'discouraged',\n",
       " 'Challenges',\n",
       " 'setbacks',\n",
       " 'failures',\n",
       " 'journey',\n",
       " 'got']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sent2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imbw_TUkTp8v"
   },
   "source": [
    "### 2.5 Lemmatization\n",
    "Lemmatization is a way of dealing with the fact that while words like connect, connection, connecting, connected, etc. aren’t exactly the same, they all have the same essential meaning: connect. The differences in spelling have grammatical functions in spoken language, but for machine processing, those differences can be confusing, so we need a way to change all the words that are forms of the word connect into the word connect itself.\n",
    "\n",
    "One method for doing this is called __stemming__. Stemming involves simply lopping off easily-identified prefixes and suffixes to produce what’s often the simplest version of a word, the root. Connection, for example, would have the -ion suffix removed and be correctly reduced to connect. This kind of simple stemming is often all that’s needed, but lemmatization—which actually looks at words and their roots (called lemma) as described in the dictionary—is more precise (e.g feet -> foot).\n",
    "\n",
    "Let's look at this simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTqSImYfTp8v",
    "outputId": "3f138cd1-f8e7-44eb-f1cf-509998d3efb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run run\n",
      "runs run\n",
      "ran run\n",
      "running run\n",
      "runner runner\n",
      "runners runner\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lem = sp(\"run runs ran running runner runners\")\n",
    "\n",
    "# Find lemma for each word\n",
    "for word in lem:\n",
    "    print(word.text, word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7J5Na4DTp84"
   },
   "source": [
    "### 2.6 Entity Detection\n",
    "\n",
    "__Entity detection__, also called entity recognition, is a more advanced form of language processing that identifies important elements like places, people, organizations, and languages within a text. This is really helpful for quickly extracting information from the text, since you can quickly pick out important topics or indentify key sections of it.\n",
    "\n",
    "Let’s try out some entity detection using a few paragraphs from this [article](https://www.bloomberg.com/features/trump-tweets-market/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nvlb9S71Tp84",
    "outputId": "713e6602-f65d-425e-801c-ee50637847fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Donald Trump, 'PERSON', 380),\n",
       " (Twitter, 'PRODUCT', 386),\n",
       " (American, 'NORP', 381),\n",
       " (U.S., 'GPE', 384),\n",
       " (late January, 'DATE', 391),\n",
       " (American, 'NORP', 381),\n",
       " (more than 10, 'CARDINAL', 397),\n",
       " (that month, 'DATE', 391)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = sp(\"\"\"\n",
    "President Donald Trump gets a lot of attention for using Twitter to attack American trading partners, political foes, and media companies. But he often takes to the platform to celebrate the strength of the world’s largest economy and its publicly-traded companies.\n",
    "\n",
    "Before U.S. stocks peaked in late January, he drew a direct connection between the increase in market value of American companies and his administration’s pro-growth policies on more than 10 occasions in that month alone.\n",
    "\"\"\")\n",
    "\n",
    "entities = [(i, i.label_, i.label) for i in article.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1ScYkq7Tp87"
   },
   "source": [
    "The above example how spaCy is able to identify a variety of different entity types, including specific locations (GPE), date-related words (DATE), important numbers (CARDINAL), specific individuals (PERSON), etc.\n",
    "\n",
    "Using `displaCy` we can also visualize the text, with each identified entity highlighted by a color and labeled. We’ll use `style=\"ent\"` to tell displaCy that we want to visualize entities here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "hGDOBT6zTp88",
    "outputId": "f3056b84-afc8-4c1a-d198-8d6ad75fa4d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " gets a lot of attention for using \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " to attack \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " trading partners, political foes, and media companies. But he often takes to the platform to celebrate the strength of the world’s largest economy and its publicly-traded companies.</br></br>Before \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " stocks peaked in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    late January\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", he drew a direct connection between the increase in market value of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " companies and his administration’s pro-growth policies on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 10\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " occasions in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    that month\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " alone.</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(article, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erd3X6Q-n1_Y"
   },
   "source": [
    "### 2.7 Exercise\n",
    "For each word in the sentence below, print its lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "zyJOSspCn7W6"
   },
   "outputs": [],
   "source": [
    "sentence = \"\"\"The happiness of your life depends upon the quality of your thoughts: therefore, guard accordingly, and take care that you entertain no notions unsuitable to virtue and reasonable nature.\"\"\"\n",
    "\n",
    "# Print lemma\n",
    "# [YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRR_jyLPp8Q2"
   },
   "source": [
    "Create two lists, the first one containing the punctuation and the second one the words (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fVwmiV9_n7SU"
   },
   "outputs": [],
   "source": [
    "# [YOUR CODE HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKE3SNk6aHvL"
   },
   "source": [
    "### 2.8 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gDVhIdRwaHAG"
   },
   "outputs": [],
   "source": [
    "# # Lemma\n",
    "# doc = sp(sentence)\n",
    "# for word in doc:\n",
    "#   print(word.text, word.lemma_)\n",
    "\n",
    "# # punct and tokens\n",
    "# punct = []\n",
    "# tokens = []\n",
    "# for word in doc:\n",
    "#   if word.is_punct == True:\n",
    "#     punct.append(word)\n",
    "#   elif word.is_space == False:\n",
    "#     tokens.append(word)\n",
    "\n",
    "# print(punct)\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QZOutDwsYij"
   },
   "source": [
    "## 3. Text Representation\n",
    "We now show how to transform a text into an usable input for text classification. We use the first sentence of the article from the last section and two other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "X2MjeqoQxdOx"
   },
   "outputs": [],
   "source": [
    "# Article as a string, not a spacy object\n",
    "article = \"\"\"\n",
    "President Donald Trump gets a lot of attention for using Twitter to attack American trading partners, political foes, and media companies.\"\"\"\n",
    "\n",
    "# Sentences\n",
    "s1 = \"\"\"Donald Trump is a great friend, and he has four or five Picassos on his plane. And that's where I would look at them.\"\"\" # from Shaquille O'Neal\n",
    "s2 = \"\"\"Donald Trump is a phony, a fraud. His promises are as worthless as a degree from Trump University.\"\"\" # from Mitt Romney\n",
    "\n",
    "# List of sentences\n",
    "texts = [article, s1, s2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCFQrtHLtMTt"
   },
   "source": [
    "### 3.1 Bag of Words (BOW)\n",
    "We use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class of scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyzBm0BUtLc0",
    "outputId": "231db08a-925c-440c-a642-90d03ad5921b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0,\n",
       "        0, 1, 1, 0, 0, 1, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using default tokenizer \n",
    "\n",
    "count = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")\n",
    "# stop_words : 'english' =>  a built-in stop word list for English is used\n",
    "\n",
    "bow = count.fit_transform(texts)\n",
    "\n",
    "# Show feature matrix\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GRmUUc0kzi3_",
    "outputId": "a3648c86-8ed3-48db-bdc7-61cac70236ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['american',\n",
       " 'american trading',\n",
       " 'attack',\n",
       " 'attack american',\n",
       " 'attention',\n",
       " 'attention using',\n",
       " 'companies',\n",
       " 'degree',\n",
       " 'degree trump',\n",
       " 'donald',\n",
       " 'donald trump',\n",
       " 'foes',\n",
       " 'foes media',\n",
       " 'fraud',\n",
       " 'fraud promises',\n",
       " 'friend',\n",
       " 'friend picassos',\n",
       " 'gets',\n",
       " 'gets lot',\n",
       " 'great',\n",
       " 'great friend',\n",
       " 'look',\n",
       " 'lot',\n",
       " 'lot attention',\n",
       " 'media',\n",
       " 'media companies',\n",
       " 'partners',\n",
       " 'partners political',\n",
       " 'phony',\n",
       " 'phony fraud',\n",
       " 'picassos',\n",
       " 'picassos plane',\n",
       " 'plane',\n",
       " 'plane look',\n",
       " 'political',\n",
       " 'political foes',\n",
       " 'president',\n",
       " 'president donald',\n",
       " 'promises',\n",
       " 'promises worthless',\n",
       " 'trading',\n",
       " 'trading partners',\n",
       " 'trump',\n",
       " 'trump gets',\n",
       " 'trump great',\n",
       " 'trump phony',\n",
       " 'trump university',\n",
       " 'twitter',\n",
       " 'twitter attack',\n",
       " 'university',\n",
       " 'using',\n",
       " 'using twitter',\n",
       " 'worthless',\n",
       " 'worthless degree']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "# View feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "sxCSvGUTz2tl",
    "outputId": "2b1273d6-433d-4f79-8d29-d07fc8e2d7a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8ee8e5b9-df24-41cd-a83e-c13518589556\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>american trading</th>\n",
       "      <th>attack</th>\n",
       "      <th>attack american</th>\n",
       "      <th>attention</th>\n",
       "      <th>attention using</th>\n",
       "      <th>companies</th>\n",
       "      <th>degree</th>\n",
       "      <th>degree trump</th>\n",
       "      <th>donald</th>\n",
       "      <th>...</th>\n",
       "      <th>trump great</th>\n",
       "      <th>trump phony</th>\n",
       "      <th>trump university</th>\n",
       "      <th>twitter</th>\n",
       "      <th>twitter attack</th>\n",
       "      <th>university</th>\n",
       "      <th>using</th>\n",
       "      <th>using twitter</th>\n",
       "      <th>worthless</th>\n",
       "      <th>worthless degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 54 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ee8e5b9-df24-41cd-a83e-c13518589556')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8ee8e5b9-df24-41cd-a83e-c13518589556 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8ee8e5b9-df24-41cd-a83e-c13518589556');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   american  american trading  attack  attack american  attention  \\\n",
       "0         1                 1       1                1          1   \n",
       "1         0                 0       0                0          0   \n",
       "2         0                 0       0                0          0   \n",
       "\n",
       "   attention using  companies  degree  degree trump  donald  ...  trump great  \\\n",
       "0                1          1       0             0       1  ...            0   \n",
       "1                0          0       0             0       1  ...            1   \n",
       "2                0          0       1             1       1  ...            0   \n",
       "\n",
       "   trump phony  trump university  twitter  twitter attack  university  using  \\\n",
       "0            0                 0        1               1           0      1   \n",
       "1            0                 0        0               0           0      0   \n",
       "2            1                 1        0               0           1      0   \n",
       "\n",
       "   using twitter  worthless  worthless degree  \n",
       "0              1          0                 0  \n",
       "1              0          0                 0  \n",
       "2              0          1                 1  \n",
       "\n",
       "[3 rows x 54 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show as a dataframe\n",
    "pd.DataFrame(\n",
    "    bow.todense(), \n",
    "    columns=feature_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7tNGrTutQ2r"
   },
   "source": [
    "### 3.2 TF-IDF Representation\n",
    "\n",
    "\n",
    "Recall that:\n",
    "\n",
    "- **term frequency tf** = count(word, document) / len(document) \n",
    "- **term frequency idf** = log( len(collection) / count(document_containing_term, collection) )\n",
    "- **tf-idf** = tf * idf \n",
    "\n",
    "  (The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.) [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "It is important to mention that the IDF value for a word remains the same throughout all the documents as it depends upon the total number of documents. On the other hand, TF values of a word differ from document to document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "djkUI6hXtWlr",
    "outputId": "26cb28a5-eb81-40ff-ebbc-48d5a6d4a621"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6f601478-db2b-415d-821a-4025d320cfaf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>american</th>\n",
       "      <th>attack</th>\n",
       "      <th>attention</th>\n",
       "      <th>companies</th>\n",
       "      <th>degree</th>\n",
       "      <th>donald</th>\n",
       "      <th>foes</th>\n",
       "      <th>fraud</th>\n",
       "      <th>friend</th>\n",
       "      <th>gets</th>\n",
       "      <th>...</th>\n",
       "      <th>plane</th>\n",
       "      <th>political</th>\n",
       "      <th>president</th>\n",
       "      <th>promises</th>\n",
       "      <th>trading</th>\n",
       "      <th>trump</th>\n",
       "      <th>twitter</th>\n",
       "      <th>university</th>\n",
       "      <th>using</th>\n",
       "      <th>worthless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.154057</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.154057</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260841</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.41894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359347</td>\n",
       "      <td>0.212236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359347</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.424472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f601478-db2b-415d-821a-4025d320cfaf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6f601478-db2b-415d-821a-4025d320cfaf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6f601478-db2b-415d-821a-4025d320cfaf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   american    attack  attention  companies    degree    donald      foes  \\\n",
       "0  0.260841  0.260841   0.260841   0.260841  0.000000  0.154057  0.260841   \n",
       "1  0.000000  0.000000   0.000000   0.000000  0.000000  0.247433  0.000000   \n",
       "2  0.000000  0.000000   0.000000   0.000000  0.359347  0.212236  0.000000   \n",
       "\n",
       "      fraud   friend      gets  ...    plane  political  president  promises  \\\n",
       "0  0.000000  0.00000  0.260841  ...  0.00000   0.260841   0.260841  0.000000   \n",
       "1  0.000000  0.41894  0.000000  ...  0.41894   0.000000   0.000000  0.000000   \n",
       "2  0.359347  0.00000  0.000000  ...  0.00000   0.000000   0.000000  0.359347   \n",
       "\n",
       "    trading     trump   twitter  university     using  worthless  \n",
       "0  0.260841  0.154057  0.260841    0.000000  0.260841   0.000000  \n",
       "1  0.000000  0.247433  0.000000    0.000000  0.000000   0.000000  \n",
       "2  0.000000  0.424472  0.000000    0.359347  0.000000   0.359347  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using default tokenizer in TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words=\"english\")\n",
    "\n",
    "features = tfidf.fit_transform(texts)\n",
    "\n",
    "pd.DataFrame(\n",
    "    features.todense(),\n",
    "    columns=tfidf.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcyNjGlfHjlo",
    "outputId": "229b04d4-c0b0-46af-d7ff-a0dbcd704974"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nPresident Donald Trump gets a lot of attention for using Twitter to attack American trading partners, political foes, and media companies.',\n",
       " \"Donald Trump is a great friend, and he has four or five Picassos on his plane. And that's where I would look at them.\",\n",
       " 'Donald Trump is a phony, a fraud. His promises are as worthless as a degree from Trump University.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcrRL3rRqgBy"
   },
   "source": [
    "### 3.3 Exercise\n",
    "Create a TF-IDF Representation of the three above sentences using bigrams and the following stopwords: [\"and\", \"a\", \"is\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fzo8uviDrTLm"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYgMIUcVbCC6"
   },
   "source": [
    "### 3.4 Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "HEUWiXjubBn_"
   },
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer(ngram_range=(2, 2), stop_words=[\"and\", \"a\", \"is\"])\n",
    "# features = tfidf.fit_transform(texts)\n",
    "# pd.DataFrame(\n",
    "#     features.todense(),\n",
    "#     columns=tfidf.get_feature_names()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARu2ONJb06Sr"
   },
   "source": [
    "## 4. Text Classification: Alexa reviews\n",
    "\n",
    "We are going to use a real-world data set: [Amazon Alexa product reviews](https://www.kaggle.com/bittlingmayer/amazonreviews).\n",
    "\n",
    "This data set comes as a tab-separated file (.tsv). It has has five columns: `rating`, `date`, `variation`, `verified_reviews`, `feedback`.\n",
    "\n",
    "`rating` denotes the rating each user gave Alexa (out of 5). `date` indicates the date of the review, and `variation` describes which model the user reviewed. `verified_reviews` contains the text of each review, and `feedback` contains a sentiment label, with 1 denoting positive sentiment (the user liked it) and 0 denoting negative sentiment (the user didn’t).\n",
    "\n",
    "We are going develop a classification model that looks at the review text and predicts whether a review is positive or negative. Since this data set already includes whether a review is positive or negative in the `feedback` column, we can use those answers to train and test our model. Our goal here is to produce an accurate model that we could then use to process new user reviews and quickly determine whether they were positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzfnR4ua2uLw"
   },
   "source": [
    "### 4.1 Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "5rS4hAiA05wQ"
   },
   "outputs": [],
   "source": [
    "# Import additional packages\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Sxrlx4eD0Ygk",
    "outputId": "43825e5b-e8f0-4fdf-e0cd-84887084f3e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2ffe56be-448c-48e9-9ca3-cc1a8afde5aa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>1</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>This worked well for about 6 months but then s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>5</td>\n",
       "      <td>7-Jul-18</td>\n",
       "      <td>Black</td>\n",
       "      <td>A great buy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>2</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Configuration: Fire TV Stick</td>\n",
       "      <td>I would not recommend this to anyone. It won't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>So far all.i can say is I love it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Use the product for music and it’s great!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>5</td>\n",
       "      <td>20-Jul-18</td>\n",
       "      <td>White  Spot</td>\n",
       "      <td>Love it, Love it, Love it!!! Bought it on Prim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>4</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>White  Dot</td>\n",
       "      <td>Barry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>5</td>\n",
       "      <td>22-Jun-18</td>\n",
       "      <td>White</td>\n",
       "      <td>Love the dots, especially with the ability to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>5</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Sandstone Fabric</td>\n",
       "      <td>Very responsive. Great sound quality for its s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>5</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>My husband and I are what I would call &amp;#34;la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ffe56be-448c-48e9-9ca3-cc1a8afde5aa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2ffe56be-448c-48e9-9ca3-cc1a8afde5aa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2ffe56be-448c-48e9-9ca3-cc1a8afde5aa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      rating       date                     variation  \\\n",
       "2611       1  30-Jul-18                    Black  Dot   \n",
       "442        5   7-Jul-18                         Black   \n",
       "2390       2  30-Jul-18  Configuration: Fire TV Stick   \n",
       "3055       5  30-Jul-18                    Black  Dot   \n",
       "3130       5  30-Jul-18                    Black  Dot   \n",
       "1335       5  20-Jul-18                   White  Spot   \n",
       "2789       4  30-Jul-18                    White  Dot   \n",
       "511        5  22-Jun-18                         White   \n",
       "284        5  29-Jul-18             Sandstone Fabric    \n",
       "963        5  29-Jul-18              Charcoal Fabric    \n",
       "\n",
       "                                       verified_reviews  feedback  \n",
       "2611  This worked well for about 6 months but then s...         0  \n",
       "442                                         A great buy         1  \n",
       "2390  I would not recommend this to anyone. It won't...         0  \n",
       "3055                  So far all.i can say is I love it         1  \n",
       "3130          Use the product for music and it’s great!         1  \n",
       "1335  Love it, Love it, Love it!!! Bought it on Prim...         1  \n",
       "2789                                              Barry         1  \n",
       "511   Love the dots, especially with the ability to ...         1  \n",
       "284   Very responsive. Great sound quality for its s...         1  \n",
       "963   My husband and I are what I would call &#34;la...         1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "url = \"https://raw.githubusercontent.com/michalis0/DataMining_and_MachineLearning/master/week9/data/amazon_alexa.tsv\"\n",
    "df = pd.read_csv(url, delimiter=\"\\t\")\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNjV_B2E3nLd",
    "outputId": "099d1c4d-84e0-416c-de3e-05360467fd78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "P6hCSlbq30UT"
   },
   "outputs": [],
   "source": [
    "# Change date to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dP8sYT2y34CU",
    "outputId": "b29888b2-c67d-477a-f92c-41d9e88cb405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   rating            3150 non-null   int64         \n",
      " 1   date              3150 non-null   datetime64[ns]\n",
      " 2   variation         3150 non-null   object        \n",
      " 3   verified_reviews  3150 non-null   object        \n",
      " 4   feedback          3150 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yK8u3mNw35HC",
    "outputId": "ede1805b-23a8-45f8-ee13-952089996958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base rate: the data-set is unbalanced!\n",
    "df.feedback.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d4NPeOq4A0X",
    "outputId": "1b52d750-f873-4cd6-b07d-aa93ada8a50a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.feedback.value_counts()[1] / len(df), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iFd7_hl4eNJ"
   },
   "source": [
    "###### Tokening the Data With spaCy\n",
    "\n",
    "We create a `spacy_tokenizer()` function that accepts a sentence as input and processes the sentence into tokens, performing lemmatization, lowercasing, and removing stopwords.\n",
    "\n",
    "__A note from spacy documentation__: spaCy adds a special case for pronouns: all pronouns are lemmatized to the special token `-PRON-`. Unlike verbs and common nouns, there’s no clear base form of a personal pronoun. Should the lemma of “me” be “I”, or should we normalize person as well, giving “it” — or maybe “he”? spaCy’s solution is to introduce a novel symbol, `-PRON-`, which is used as the lemma for all personal pronouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "hrHhCTFN5ZXw",
    "outputId": "5f0de137-34fb-497e-a19e-578c706652c4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QCVM6xVQ5fP2",
    "outputId": "be358057-caf7-4589-c184-a1a7449df338"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eight',\n",
       " 'to',\n",
       " 'somewhere',\n",
       " 'rather',\n",
       " 'before',\n",
       " 'became',\n",
       " 'ours',\n",
       " 'also',\n",
       " 'by',\n",
       " 'where']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of stopwords\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "-_ALYORw4LN0",
    "outputId": "e6ae381d-e60b-4ccf-f847-b7fe1b2128dc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load English language model\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Create token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = sp(sentence)\n",
    "\n",
    "    # Lemmatize each token and convert each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in mytokens ]\n",
    "    ## alternative way\n",
    "    # mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # Return preprocessed list of tokens\n",
    "    return mytokens\n",
    "\n",
    "# Example\n",
    "review = df[\"verified_reviews\"].sample()\n",
    "review.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dlOwdF_16JV-",
    "outputId": "48d5b056-360d-4fce-8bf4-71177bfe6d48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenizer(review.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "MmZZIAFsydPU",
    "outputId": "cc800c91-11c0-4229-ee5a-f64a4a69296e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'I love this its super convenient and makes my life a little easier'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2982, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8n5Eky4kyyxp",
    "outputId": "1f3ab8de-8a22-4dc5-825e-5edc23e5f5e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'super', 'convenient', 'life', 'little', 'easy']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_tokenizer(df.iloc[2982, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ5Yl8uR9eYv"
   },
   "source": [
    "#### Vectorization Feature Engineering (TF-IDF)\n",
    "\n",
    "We use the TF-IDF (Term Frequency-Inverse Document Frequency) to vectorize the documents. This is a way of representing how important a particular term is in the context of a given document, based on how many times the term appears and how many other documents that same term appears in. The higher the TF-IDF, the more important that term is to that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "0-874sxt8iNM"
   },
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jO56WUV9yXn"
   },
   "source": [
    "### 4.2 Classification of the reviews using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7JkcGTb9ty9",
    "outputId": "40ff5d3d-d80b-4878-9650-7bc8901ae5a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1529               I agree ...YouTube should be on there.\n",
       "641                                   Love my echo dot!!!\n",
       "2831                                         Nice product\n",
       "3086    Works as expected. This is our fourth one, our...\n",
       "1262    Bought this for our son as his birthday presen...\n",
       "                              ...                        \n",
       "350     Item no longer works after just 5 months of us...\n",
       "786                        The speaker sounds really good\n",
       "2440    This thing is great if you have internet and a...\n",
       "355                                      Works just fine.\n",
       "3025    Listens well, does way more than expected, lov...\n",
       "Name: verified_reviews, Length: 2520, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features\n",
    "X = df['verified_reviews'] # the features we want to analyze\n",
    "ylabels = df['feedback'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P6dbSYsF-HRi",
    "outputId": "beb5b07d-32eb-4299-d519-a49d0c9b33eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1529    1\n",
       "641     1\n",
       "2831    1\n",
       "3086    1\n",
       "1262    1\n",
       "       ..\n",
       "350     0\n",
       "786     1\n",
       "2440    1\n",
       "355     1\n",
       "3025    1\n",
       "Name: feedback, Length: 2520, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dB8PkfsP-JYi",
    "outputId": "7b652bd1-345a-43c3-8687-89b058e29d73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function spacy_tokenizer at 0x7f9d00d4ac20>)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define classifier\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline\n",
    "## The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "e07kHgHb-hC2"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate(true, pred):\n",
    "    precision = precision_score(true, pred)\n",
    "    recall = recall_score(true, pred)\n",
    "    f1 = f1_score(true, pred)\n",
    "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(true, pred)}\")\n",
    "    print(f\"ACCURACY SCORE:\\n{accuracy_score(true, pred):.4f}\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n\\tPrecision: {precision:.4f}\\n\\tRecall: {recall:.4f}\\n\\tF1_Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PjJWqHp_HvQ",
    "outputId": "94b1a01e-555c-4f9b-d07b-a713cf630ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluation - test set\n",
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRrITD4y_nbb"
   },
   "source": [
    "For the test set, the model correctly identifies a sentiment 91.90% of the time. This is almost the same as the base rate (91.84%). Therefore, the model does not work very well. This may be due to the fact that we have an unbalanced sample with too much positive reviews. Maybe the model cannot learn how to classify negative reviews well since there are too few examples of them.\n",
    "\n",
    "A recall of 1 means that if a sentiment is positive, it will be classififed as positive.\n",
    "\n",
    "We observe approximately the same on the training set, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeB_oSPKP7vZ",
    "outputId": "0ed27ff2-f0e2-4167-f14e-83e8b9ee700c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[  14  192]\n",
      " [   0 2314]]\n",
      "ACCURACY SCORE:\n",
      "0.9238\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9234\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9602\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "evaluate(y_train, pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZAzALsgXu_v",
    "outputId": "db47600f-33a8-4ad0-a343-a8f5ac45a67a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: verified_reviews, dtype: object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which reviews are classified as negative in test set?\n",
    "X_test.loc[pipe.predict(X_test) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBMomG3RYeo2",
    "outputId": "a1325356-b573-40db-ca25-e92398b2e04c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['product stopped working after return time ran out',\n",
       "       \"It worked for a month or so then it stopped. I've tried everything to try and make it work but nothing is working. I want a refund\",\n",
       "       \"I've already returned it.\",\n",
       "       'Terrible. Stopped working after one day.',\n",
       "       'Bought this for my son and it didn’t work. He had to return it.',\n",
       "       \"Why do we need to buy a $100 hub to get it to work with Samsung TV's and many other devices?  I want my money back!  This thing won't even turn on my TV unless I buy another hub.  What's the point of having a hub that doesn't support half the devices out there?  DON'T buy this thing unless you want to spend another $100 on another hub.  It won't work with many of your devices.  Just by the Echo or Dot if you must but not this.  Better yet, get a Google device.  They actually understand you when you talk.\",\n",
       "       'Item has never worked. Out of box it is broken. Spent several days trying to get it working and running same &#34;fixes&#34; from Amazon. The only thing accomplished is I will never order another refurbished device.',\n",
       "       'I set up the Echo Dot and it worked for an hour and then died completely. DO NOT BUY refurbished!!!! I sent back for return the day after I received.',\n",
       "       'I returned 2 Echo Dots & am only getting refund for 1. I returned 2 in one package. I want my refunds for both of them. They are in the same package. Can you not see them both???!!!',\n",
       "       \"This worked well for about 6 months but then stopped connecting to the internet (wifi) and none of the trouble shooting efforts worked.  Amazon customer service couldn't help further and told me warranty was only 3 months, which was very disappointing, so they weren't willing to replace.\",\n",
       "       'This item did not work. Certified refurbished should mean it works as advertised. Instead this item crashed as soon as I turned it on and plugged it in. When trying to connect from my phone to the echo dot, it crashed, over and over. Not only would it disconnect but the orange light would freeze and then the thing would reboot with the blue light. Alexa would tell me it’s ready to connect and freeze mid sentence. Tried holding the action button for 5 seconds and it didn’t do anything. Returning immediately and hope they actually fix this item when the next buyer purchases it.',\n",
       "       \"This worked well for about 6 months but then stopped connecting to the internet (wifi) and none of the trouble shooting efforts worked.  Amazon customer service couldn't help further and told me warranty was only 3 months, which was very disappointing, so they weren't willing to replace.\",\n",
       "       \"Can't turn of &#34;things to try&#34; on the screen scroll. This  is a big promotion device for Amazon.  Packing it up and sending it back.  They really want to get in our heads.  Enough already.\",\n",
       "       'Bought 2 and both quit connecting to wifi and responding to voice within 9 months. Hard and soft reset will not fix the problem.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which reviews are classified as negaive in training set?\n",
    "X_train.loc[pipe.predict(X_train) == 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SnrtzOhS9cP",
    "outputId": "f9c447da-0603-45fc-90de-39fdd84a97eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I really love the product. It is very helpful....\n",
       "1              It stopped working, I want to return it\n",
       "2                           I don't like it, it is bad\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for new reviews\n",
    "example_review_1 = \"I really love the product. It is very helpful. I use it everyday\" # positive\n",
    "example_review_2 = \"It stopped working, I want to return it\" # negative\n",
    "example_review_3 = \"I don't like it, it is bad\" # negative\n",
    "\n",
    "examples = pd.Series([example_review_1, example_review_2, example_review_3])\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yrnvd-ZPT7aR",
    "outputId": "91af0854-2eaa-4b7c-fb28-be0c2203156e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHne-tgCScWk"
   },
   "source": [
    "### 4.3 How can we improve the accuracy?\n",
    "In order to improve the prediction, we can try to:\n",
    "* Resample our data (i.e. add negative examples for better training)\n",
    "* Tune the hyperparameters of the model\n",
    "* Improve text preparation\n",
    "* Use another classififer\n",
    "\n",
    "We illustrate how to improve text preparation, resampling, and the use of another classifier below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyEyaUltsGNB"
   },
   "source": [
    "#### 4.3.1 Improve text preparation\n",
    "The purpose here is to optimize the parameters of the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0KXBFJyuKWn",
    "outputId": "df8087b1-30d7-484e-d85d-d21a9781d449"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1, 1), 1, 1.0, 'word'],\n",
       " [(1, 1), 1, 1.0, 'char'],\n",
       " [(1, 2), 1, 1.0, 'word'],\n",
       " [(1, 2), 1, 1.0, 'char'],\n",
       " [(1, 3), 1, 1.0, 'word'],\n",
       " [(1, 3), 1, 1.0, 'char'],\n",
       " [(2, 2), 1, 1.0, 'word'],\n",
       " [(2, 2), 1, 1.0, 'char'],\n",
       " [(2, 3), 1, 1.0, 'word'],\n",
       " [(2, 3), 1, 1.0, 'char']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of configs\n",
    "def configs():\n",
    "\n",
    "    models = list()\n",
    "    \n",
    "    # Define config lists\n",
    "    ngram_range = [(1,1), (1,2), (1, 3), (2, 2), (2, 3), (3, 3)]\n",
    "    min_df = [1]\n",
    "    max_df = [1.0]\n",
    "    analyzer=['word', 'char']\n",
    "    \n",
    "    # Create config instances\n",
    "    for n in ngram_range:\n",
    "        for i in min_df:\n",
    "            for j in max_df:\n",
    "              for a in analyzer:\n",
    "                    cfg = [n, i, j, a]\n",
    "                    models.append(cfg)\n",
    "    return models\n",
    "\n",
    "configs = configs()\n",
    "configs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zypqialXQZTZ",
    "outputId": "2ef7cc1c-49a8-41f9-9381-67053055c787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFIG:  [(1, 1), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(1, 1), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(1, 2), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(1, 2), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  1 578]]\n",
      "ACCURACY SCORE:\n",
      "0.9175\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9189\n",
      "\tRecall: 0.9983\n",
      "\tF1_Score: 0.9570\n",
      "-----------------------\n",
      "CONFIG:  [(1, 3), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(1, 3), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(2, 2), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(2, 2), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  1  50]\n",
      " [  1 578]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9204\n",
      "\tRecall: 0.9983\n",
      "\tF1_Score: 0.9577\n",
      "-----------------------\n",
      "CONFIG:  [(2, 3), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(2, 3), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  1 578]]\n",
      "ACCURACY SCORE:\n",
      "0.9175\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9189\n",
      "\tRecall: 0.9983\n",
      "\tF1_Score: 0.9570\n",
      "-----------------------\n",
      "CONFIG:  [(3, 3), 1, 1.0, 'word']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n",
      "CONFIG:  [(3, 3), 1, 1.0, 'char']\n",
      "CONFUSION MATRIX:\n",
      "[[  0  51]\n",
      " [  0 579]]\n",
      "ACCURACY SCORE:\n",
      "0.9190\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9190\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9578\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# Define list for result\n",
    "result = []\n",
    "\n",
    "for config in configs:\n",
    "\n",
    "    # Redefine vectorizer\n",
    "    tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer, \n",
    "                                   ngram_range=config[0],\n",
    "                                   min_df=config[1], max_df=config[2], analyzer=config[3])\n",
    "\n",
    "    # Define classifier\n",
    "    classifier = LogisticRegression()\n",
    "\n",
    "    # Create pipeline\n",
    "    pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "    # Fit model on training set\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # Print accuracy on test set\n",
    "    print(\"CONFIG: \", config)\n",
    "    evaluate(y_test, y_pred)\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    # Append to result\n",
    "    result.append([config, accuracy_score(y_test, y_pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Boqm0jsz4CvZ"
   },
   "source": [
    "Our tries do not work, we have to try further or use something else to improve prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pygcSii_4SF4"
   },
   "source": [
    "#### 4.3.2 Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "L27GTYuFNRJU",
    "outputId": "2d2c1a1c-cc7b-445e-90d3-6968c8f8c253"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-dff7444a-af78-41d6-ac33-80d3d7725273\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2868</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>My new best friend!! I'm a little behind the t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1881</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>White  Plus</td>\n",
       "      <td>Although this is my second echo device, I am s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>White  Spot</td>\n",
       "      <td>Well-made product.Echo Spot - White</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Glad I bought this.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-07-29</td>\n",
       "      <td>Sandstone Fabric</td>\n",
       "      <td>Like it to do more</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>3047</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Echo Dot responds to us when we aren't even ta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>3048</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>White  Dot</td>\n",
       "      <td>NOT CONNECTED TO MY PHONE PLAYLIST :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>3067</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>The only negative we have on this product is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3091</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>I didn’t order it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>3096</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>White  Dot</td>\n",
       "      <td>The product sounded the same as the emoji spea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>514 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dff7444a-af78-41d6-ac33-80d3d7725273')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-dff7444a-af78-41d6-ac33-80d3d7725273 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-dff7444a-af78-41d6-ac33-80d3d7725273');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     index  rating       date          variation  \\\n",
       "0     2868       5 2018-07-30         Black  Dot   \n",
       "1     1881       3 2018-07-28        White  Plus   \n",
       "2     1367       5 2018-07-18        White  Spot   \n",
       "3     1030       5 2018-07-28   Charcoal Fabric    \n",
       "4      240       4 2018-07-29  Sandstone Fabric    \n",
       "..     ...     ...        ...                ...   \n",
       "509   3047       1 2018-07-30         Black  Dot   \n",
       "510   3048       1 2018-07-30         White  Dot   \n",
       "511   3067       2 2018-07-30         Black  Dot   \n",
       "512   3091       1 2018-07-30         Black  Dot   \n",
       "513   3096       1 2018-07-30         White  Dot   \n",
       "\n",
       "                                      verified_reviews  feedback  \n",
       "0    My new best friend!! I'm a little behind the t...         1  \n",
       "1    Although this is my second echo device, I am s...         1  \n",
       "2                  Well-made product.Echo Spot - White         1  \n",
       "3                                  Glad I bought this.         1  \n",
       "4                                   Like it to do more         1  \n",
       "..                                                 ...       ...  \n",
       "509  Echo Dot responds to us when we aren't even ta...         0  \n",
       "510              NOT CONNECTED TO MY PHONE PLAYLIST :(         0  \n",
       "511  The only negative we have on this product is t...         0  \n",
       "512                                  I didn’t order it         0  \n",
       "513  The product sounded the same as the emoji spea...         0  \n",
       "\n",
       "[514 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create balanced dataframe - base rate = 0.5\n",
    "df_new = pd.concat([df[df[\"feedback\"] == 1].sample(len(df[df[\"feedback\"] == 0])), df[df[\"feedback\"] == 0]], axis=0).reset_index()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzVuGW63NRF3",
    "outputId": "e3c91673-c243-48ce-dfd7-c771c01c334c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[41 10]\n",
      " [10 42]]\n",
      "ACCURACY SCORE:\n",
      "0.8058\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.8077\n",
      "\tRecall: 0.8077\n",
      "\tF1_Score: 0.8077\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "X = df_new['verified_reviews'] # the features we want to analyze\n",
    "ylabels = df_new['feedback'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X, ylabels, test_size=0.2, random_state=1234, stratify=ylabels)\n",
    "\n",
    "# Define classifier\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train_b, y_train_b)\n",
    "\n",
    "# Predictions\n",
    "y_pred_b = pipe.predict(X_test_b)\n",
    "\n",
    "# Evaluation - test set\n",
    "evaluate(y_test_b, y_pred_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBKezH2Ctl3y"
   },
   "source": [
    "#### 4.3.3 Use another classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRze7VxPzZ14",
    "outputId": "d6a86bba-77d1-4e7f-a68b-827147c18992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[  9  42]\n",
      " [  1 578]]\n",
      "ACCURACY SCORE:\n",
      "0.9317\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9323\n",
      "\tRecall: 0.9983\n",
      "\tF1_Score: 0.9641\n",
      "CONFUSION MATRIX:\n",
      "[[ 188   18]\n",
      " [   0 2314]]\n",
      "ACCURACY SCORE:\n",
      "0.9929\n",
      "CLASSIFICATION REPORT:\n",
      "\tPrecision: 0.9923\n",
      "\tRecall: 1.0000\n",
      "\tF1_Score: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# Use random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define vectorizer\n",
    "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenizer) # we use the above defined tokenizer\n",
    "\n",
    "# Define classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Fit model on training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluation - test set\n",
    "evaluate(y_test, y_pred)\n",
    "\n",
    "# Evaluation - training set\n",
    "evaluate(y_train, pipe.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2I-HjNh5aTF"
   },
   "source": [
    "Of course, combining the three above-mentioned techniques should give the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Io3YM1jV1YN3"
   },
   "source": [
    "#### BONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "L9D5xSc5_y9i",
    "outputId": "179fa745-514a-4aaa-d8aa-d828b90522a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f4315289-524c-4f7c-8654-f272506d0c31\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>This was an impulse buy but turns out I really...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-29</td>\n",
       "      <td>Heather Gray Fabric</td>\n",
       "      <td>Have Alexa throughout the house----the future ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>It is just not as loud as I thought it was goi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>Heather Gray Fabric</td>\n",
       "      <td>Very cool product. Speaker sounds good with my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>White  Show</td>\n",
       "      <td>Love the echo show</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4315289-524c-4f7c-8654-f272506d0c31')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f4315289-524c-4f7c-8654-f272506d0c31 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f4315289-524c-4f7c-8654-f272506d0c31');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      rating       date             variation  \\\n",
       "2845       5 2018-07-30            Black  Dot   \n",
       "260        5 2018-07-29  Heather Gray Fabric    \n",
       "3115       5 2018-07-30            Black  Dot   \n",
       "127        5 2018-07-30  Heather Gray Fabric    \n",
       "1550       5 2018-07-30           White  Show   \n",
       "\n",
       "                                       verified_reviews  feedback  \n",
       "2845  This was an impulse buy but turns out I really...         1  \n",
       "260   Have Alexa throughout the house----the future ...         1  \n",
       "3115  It is just not as loud as I thought it was goi...         1  \n",
       "127   Very cool product. Speaker sounds good with my...         1  \n",
       "1550                                 Love the echo show         1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BONUS: predict the rating\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CiyyP7T6Bykf",
    "outputId": "12792089-e3b6-488c-e148-65a1b472ada5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2286\n",
       "4     455\n",
       "1     161\n",
       "3     152\n",
       "2      96\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BNNejlJgB2aY",
    "outputId": "b545dabf-6411-4a7e-ed65-34638108a71d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7257"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base rate\n",
    "round(df.rating.value_counts()[5] / len(df), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZE1JqorB9Lb",
    "outputId": "0b0f1635-2cc3-49cf-ff75-47ccfca18d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[  2   0   0   4  31]\n",
      " [  1   1   0   2  10]\n",
      " [  0   0   0   3  32]\n",
      " [  0   0   0   6  86]\n",
      " [  0   0   0   5 447]]\n",
      "ACCURACY SCORE:\n",
      "0.7238\n"
     ]
    }
   ],
   "source": [
    "# Select features\n",
    "X = df['verified_reviews'] # the features we want to analyze\n",
    "y = df['rating'] # the labels, or answers, we want to test against\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Define classifier\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Generate Model on training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluation - test set\n",
    "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfE1iXi0Eeuz",
    "outputId": "b16b2e00-a5fd-47f0-fb6d-975fd03481a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX:\n",
      "[[  6   1   0   1  29]\n",
      " [  1   4   0   0   9]\n",
      " [  1   0  12   2  20]\n",
      " [  1   0   0  35  56]\n",
      " [  1   0   0   2 449]]\n",
      "ACCURACY SCORE:\n",
      "0.8032\n"
     ]
    }
   ],
   "source": [
    "# BONUS 2: use random forest\n",
    "\n",
    "# Define classifier\n",
    "classifier = RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "# Create pipeline\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# Generate Model on training set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Evaluation - test set\n",
    "print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_pred):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
